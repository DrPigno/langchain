{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "639559f5",
   "metadata": {},
   "source": [
    "# Lezione 2: Agenti Avanzati e Integrazioni\n",
    "\n",
    "Benvenuti alla seconda lezione! In questo notebook imparerete:\n",
    "\n",
    "1. üåê **Ricerca Web**: Agente con Tavily per cercare informazioni online\n",
    "2. üìù **Summarize Middleware**: Riassumere conversazioni lunghe automaticamente\n",
    "3. ü§ù **Human-in-the-Loop**: Intervento umano nelle decisioni dell'agente\n",
    "4. üóÑÔ∏è **SQL Agent**: Interrogare database con linguaggio naturale\n",
    "5. üìö **RAG**: Retrieval Augmented Generation con PDF e Faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b8aa36",
   "metadata": {},
   "source": [
    "## Setup Iniziale\n",
    "\n",
    "Verifichiamo l'ambiente e carichiamo le dipendenze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccd1d6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.13.11 (main, Dec 17 2025, 21:09:15) [MSC v.1944 64 bit (AMD64)]\n",
      "‚úÖ OpenAI API key trovata\n",
      "‚úÖ Tavily API key trovata\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carica variabili d'ambiente\n",
    "load_dotenv()\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Verifica API keys\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"‚úÖ OpenAI API key trovata\")\n",
    "if os.getenv(\"TAVILY_API_KEY\"):\n",
    "    print(\"‚úÖ Tavily API key trovata\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Tavily API key non trovata - necessaria per ricerca web\")\n",
    "    print(\"   Registrati su https://tavily.com per ottenere una chiave gratuita\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cab60f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modello inizializzato\n"
     ]
    }
   ],
   "source": [
    "# Inizializza il modello\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\n",
    "    \"openai:gpt-4o-mini\",  # Usiamo un modello pi√π potente per questi task\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Modello inizializzato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df110bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# con Cerebras\n",
    "from langchain_cerebras import ChatCerebras\n",
    "\n",
    "model = ChatCerebras(model_name=\"gpt-oss-120b\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec59317",
   "metadata": {},
   "source": [
    "## 1. üåê Agente con Ricerca Web (Tavily)\n",
    "\n",
    "**Tavily** √® un motore di ricerca ottimizzato per LLM che fornisce risultati strutturati e pertinenti.\n",
    "\n",
    "**Vantaggi:**\n",
    "- Risultati ottimizzati per AI (non HTML grezzo)\n",
    "- Pi√π veloce di Google Search\n",
    "- Filtra automaticamente contenuti irrilevanti\n",
    "- Piano gratuito disponibile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdd83d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tool Tavily Search creato\n",
      "Nome tool: tavily_search_results_json\n",
      "Descrizione: A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events. Input should be a search query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pigno\\AppData\\Local\\Temp\\ipykernel_15452\\408747139.py:7: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.\n",
      "  search = TavilySearchResults(\n"
     ]
    }
   ],
   "source": [
    "# Installazione Tavily (se necessario)\n",
    "# uv pip install langchain-community tavily-python\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Creiamo il tool di ricerca\n",
    "search = TavilySearchResults(\n",
    "    max_results=3,  # Numero massimo di risultati\n",
    "    search_depth=\"advanced\",  # \"basic\" o \"advanced\"\n",
    "    include_answer=True,  # Include una risposta sintetica\n",
    "    include_raw_content=False,  # Non includere HTML grezzo\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Tool Tavily Search creato\")\n",
    "print(f\"Nome tool: {search.name}\")\n",
    "print(f\"Descrizione: {search.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd0eb276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì∞ Risultati della ricerca:\n",
      "\n",
      "1. Ces 2026, l'intelligenza artificiale √® dappertutto. Ma bisogna saperla ...\n",
      "   URL: https://www.wired.it/article/ces-2026-intelligenza-artificiale-banco-di-prova-novita/\n",
      "   Snippet: √à plausibile che molti nel settore siano in attesa di vedere che forma prender√† la strategia di OpenAI sui dispositivi. L‚Äôazienda ha gi√† fatto sapere ...\n",
      "\n",
      "2. 2026, quando l'Intelligenza artificiale diventa infrastruttura mentale e ...\n",
      "   URL: https://www.rainews.it/articoli/2025/12/2026-quando-lintelligenza-artificiale-diventa-infrastruttura-mentale-e-ridefinisce-il-potere-umano-ecdeaa4d-e460-42a4-96fc-b87621606277.html\n",
      "   Snippet: possibile. Questo atteggiamento porta a un'omologazione del pensiero e a una perdita di identit√† creativa. La discriminante sar√† quindi la capacit√† di...\n",
      "\n",
      "3. CES 2026: rivoluzione o marketing? L'intelligenza artificiale alla ...\n",
      "   URL: https://www.ilsole24ore.com/art/ces-2026-rivoluzione-o-marketing-l-intelligenza-artificiale-prova-fatti-AI6JHjc\n",
      "   Snippet: LAS VEGAS (Usa) - Quest‚Äôanno la missione del giornalista di scienza e tecnologia al Consumer Electronic Show di Las Vegas √® diversa dal solito. La pi√π...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test diretto del tool\n",
    "result = search.invoke({\"query\": \"Ultime notizie sull'intelligenza artificiale 2026\"})\n",
    "\n",
    "print(\"üì∞ Risultati della ricerca:\\n\")\n",
    "for i, res in enumerate(result, 1):\n",
    "    print(f\"{i}. {res.get('title', 'N/A')}\")\n",
    "    print(f\"   URL: {res.get('url', 'N/A')}\")\n",
    "    print(f\"   Snippet: {res.get('content', 'N/A')[:150]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d225ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agente di ricerca web creato con la nuova API!\n"
     ]
    }
   ],
   "source": [
    "# Creiamo un agente con ricerca web usando la nuova API\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "search_agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[search],\n",
    "    system_prompt=\"\"\"Sei un assistente di ricerca intelligente.\n",
    "    \n",
    "Quando l'utente fa una domanda:\n",
    "1. Usa il tool di ricerca per trovare informazioni aggiornate\n",
    "2. Analizza i risultati e sintetizzali\n",
    "3. Fornisci una risposta completa citando le fonti\n",
    "4. Se le informazioni non sono sufficienti, dillo chiaramente\n",
    "\n",
    "Rispondi sempre in italiano.\"\"\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Agente di ricerca web creato con la nuova API!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35b90f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Risposta dell'agente:\n",
      "\n",
      "**Novit√† pi√π importanti di LangChain nel 2026**\n",
      "\n",
      "Nel 2026 il framework **LangChain** ha consolidato la sua posizione di riferimento per la costruzione di agenti intelligenti, passando da una fase di rapida sperimentazione a una maturit√† orientata all‚Äôuso enterprise. Le principali innovazioni introdotte (o in fase di consolidamento) sono le seguenti:\n",
      "\n",
      "| Area | Novit√† / Evoluzione | Impatto pratico |\n",
      "|------|----------------------|-----------------|\n",
      "| **LangGraph** (sottoprogetto di LangChain) | ‚Ä¢ √à passato dalla fase ‚Äúbeta‚Äù (maggio‚ÄØ2025) a una piattaforma stabile e pi√π **maturata**. <br>‚Ä¢ Supporta workflow a lungo termine, checkpoint persistenti e **pausa per approvazione umana**. <br>‚Ä¢ Introduzione di protocolli **A2A (Agent‚Äëto‚ÄëAgent)** e **MCP** per la comunicazione cross‚Äëframework. | Consente di costruire agenti complessi che possono continuare l‚Äôesecuzione anche dopo riavvii, gestire flussi di lavoro regolamentati e collaborare con altri agenti in modo standardizzato. |\n",
      "| **LangSmith (osservabilit√†)** | ‚Ä¢ Integrazione pi√π profonda con **tracciamento, visualizzazione e valutazione** delle esecuzioni. <br>‚Ä¢ Nuove dashboard per monitorare metriche di accuratezza, latenza e conformit√†. | Gli sviluppatori e i team di prodotto ottengono insight granulari su performance e errori, facilitando il debugging e la certificazione di sistemi critici. |\n",
      "| **Human‚Äëin‚Äëthe‚ÄëLoop (HITL)** | ‚Ä¢ Strutture ‚Äú**guardrail nodes**‚Äù e UI dedicate (es. **Agent Inbox**) per inserire facilmente interventi umani, approvazioni o correzioni durante l‚Äôesecuzione dell‚Äôagente. | Aumenta la sicurezza e la fiducia in scenari ad alto rischio (finanza, sanit√†, compliance), riducendo il rischio di decisioni autonome non controllate. |\n",
      "| **Integrazioni pi√π profonde** | ‚Ä¢ Supporto a **25+ modelli di embedding** e **50+ database vettoriali**. <br>‚Ä¢ Loader per documenti da cloud (Google‚ÄØDrive, Dropbox), SaaS (Notion, Slack, Gmail) e database tradizionali. <br>‚Ä¢ Compatibilit√† ‚Äúmodel‚Äëagnostic‚Äù con LLM on‚Äëpremise o private‚Äëcloud. | Riduce il tempo di sviluppo per connettere fonti dati eterogenee e permette di cambiare provider LLM senza riscrivere il codice dell‚Äôagente. |\n",
      "| **Stabilit√† della versione 1.0** | ‚Ä¢ Rilascio **1.0 stabile** a ottobre‚ÄØ2025 con **garanzia di nessuna breaking change** fino alla 2.0. <br>‚Ä¢ Focus su **affidabilit√† a lungo termine** per deployment in produzione. | Rende LangChain pi√π adatto a progetti enterprise dove la continuit√† dell‚ÄôAPI √® cruciale. |\n",
      "| **‚ÄúAmbient Agents‚Äù** | ‚Ä¢ Visione di agenti **continui** che operano in background, eseguendo compiti proattivi (es. assistente email autonomo mostrato a gennaio‚ÄØ2025). <br>‚Ä¢ Pianificazione e UI per gestire pi√π agenti simultanei. | Sposta il paradigma da ‚Äúrichiesta‚Äërisposta‚Äù a ‚Äúassistente permanente‚Äù, aprendo nuove opportunit√† per automazione continua. |\n",
      "| **Guardrail & Compliance** | ‚Ä¢ Nodi di **filtraggio contenuti, rate‚Äëlimiting e logging di conformit√†** integrati nella piattaforma. <br>‚Ä¢ Supporto nativo per **persistenza cloud‚Äënative** (checkpointing su servizi gestiti oltre a PostgreSQL/Redis). | Aiuta le organizzazioni a rispettare normative (GDPR, HIPAA, ecc.) e a gestire carichi di lavoro su infrastrutture cloud senza dover implementare soluzioni ad hoc. |\n",
      "\n",
      "### Fonti\n",
      "\n",
      "1. **Teqnovos ‚Äì ‚ÄúHow LangChain Development is Leading AI Orchestration in 2026‚Äù** ‚Äì descrive le integrazioni pi√π profonde, l‚Äôosservabilit√† avanzata di LangSmith, il supporto Human‚Äëin‚Äëthe‚ÄëLoop e la crescita di LangGraph.„Äê1‚Ä†L2-L9„Äë„Äê1‚Ä†L10-L15„Äë  \n",
      "2. **ClickUp ‚Äì ‚ÄúWhy LangChain Agentic AI Is Gaining Ground Fast in 2026‚Äù** ‚Äì evidenzia il rilascio stabile 1.0, la visione degli ‚Äúambient agents‚Äù, le integrazioni con modelli e database, e le nuove UI per la gestione degli agenti.„Äê2‚Ä†L9-L16„Äë„Äê2‚Ä†L17-L24„Äë  \n",
      "3. **AgentFrameworkHub ‚Äì ‚ÄúLangGraph 2026: Breaking Changes, Features & More‚Äù** ‚Äì elenca le novit√† di LangGraph (protocollo A2A, osservabilit√† LangSmith, guardrail nodes, persistenza cloud‚Äënative).„Äê3‚Ä†L1-L8„Äë„Äê3‚Ä†L9-L14„Äë\n",
      "\n",
      "### Sintesi\n",
      "\n",
      "Nel 2026 LangChain si √® trasformato da un set di primitive per la costruzione di agenti a una **piattaforma completa per l‚Äôorchestrazione AI enterprise**. Le innovazioni chiave ‚Äì **LangGraph evoluto, osservabilit√† LangSmith, integrazioni estese, supporto Human‚Äëin‚Äëthe‚ÄëLoop, stabilit√† della versione 1.0 e la strategia ‚Äúambient agents‚Äù** ‚Äì consentono di creare sistemi agentici pi√π **affidabili, monitorabili, conformi e pronti per l‚Äôuso continuo**. Queste evoluzioni rispondono alle esigenze delle grandi organizzazioni che richiedono **scalabilit√†, governance e capacit√† di integrazione** con le loro infrastrutture esistenti.\n"
     ]
    }
   ],
   "source": [
    "# Testiamo l'agente di ricerca\n",
    "response = search_agent.invoke({\n",
    "    \"messages\": \"Quali sono le novit√† pi√π importanti di LangChain nel 2026?\"\n",
    "})\n",
    "\n",
    "print(\"ü§ñ Risposta dell'agente:\\n\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b85884",
   "metadata": {},
   "source": [
    "## 2. üìù Summarize Middleware\n",
    "\n",
    "Per conversazioni lunghe, la **SummarizationMiddleware** riassume automaticamente i messaggi pi√π vecchi per risparmiare token e mantenere il contesto gestibile.\n",
    "\n",
    "**Quando usarlo:**\n",
    "- Conversazioni molto lunghe (> 20-30 messaggi)\n",
    "- Limiti di contesto del modello\n",
    "- Costi elevati per token\n",
    "\n",
    "- Token counter configurabile\n",
    "\n",
    "**Novit√† con la nuova API:**- Gestione automatica di coppie AI/Tool message\n",
    "\n",
    "- Middleware ufficiale da `langchain.agents.middleware.summarization`- Supporto per trigger multipli (token, messaggi, frazione)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "950c2fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SummarizationMiddleware avanzato creato\n",
      "\n",
      "üîÆ Modalit√† di trigger disponibili:\n",
      "   - ('messages', N): Numero di messaggi\n",
      "   - ('tokens', N): Numero di token assoluti\n",
      "   - ('fraction', F): Frazione del contesto del modello (0.0-1.0)\n",
      "\n",
      "üîÆ Modalit√† di keep disponibili:\n",
      "   - ('messages', N): Mantieni N messaggi recenti\n",
      "   - ('tokens', N): Mantieni N token recenti\n",
      "   - ('fraction', F): Mantieni F frazione del contesto\n"
     ]
    }
   ],
   "source": [
    "# Esempio di configurazione avanzata con trigger multipli\n",
    "from langchain.agents.middleware.summarization import SummarizationMiddleware\n",
    "\n",
    "# Trigger quando SI VERIFICA UNA delle condizioni:\n",
    "advanced_summarization = SummarizationMiddleware(\n",
    "    model=model,\n",
    "    trigger=[\n",
    "        (\"messages\", 50),   # O quando raggiungi 50 messaggi\n",
    "        (\"tokens\", 4000),   # O quando raggiungi 4000 token\n",
    "        #(\"fraction\", 0.8)   # O quando usi l'80% del contesto del modello se supportato\n",
    "    ],\n",
    "    keep=(\"tokens\", 2000),  # Mantieni gli ultimi 2000 token\n",
    "    # token_counter: funzione custom per contare i token (opzionale)\n",
    ")\n",
    "\n",
    "print(\"‚úÖ SummarizationMiddleware avanzato creato\")\n",
    "print(\"\\nüîÆ Modalit√† di trigger disponibili:\")\n",
    "print(\"   - ('messages', N): Numero di messaggi\")\n",
    "print(\"   - ('tokens', N): Numero di token assoluti\")\n",
    "print(\"   - ('fraction', F): Frazione del contesto del modello (0.0-1.0)\")\n",
    "print(\"\\nüîÆ Modalit√† di keep disponibili:\")\n",
    "print(\"   - ('messages', N): Mantieni N messaggi recenti\")\n",
    "print(\"   - ('tokens', N): Mantieni N token recenti\")\n",
    "print(\"   - ('fraction', F): Mantieni F frazione del contesto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e3781e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Middleware di summarization creato\n",
      "   - Keep: ('messages', 2)\n",
      "   - Trigger: ('messages', 5)\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware.summarization import SummarizationMiddleware\n",
    "\n",
    "# Creiamo un checkpointer per la memoria\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Creiamo il middleware di summarization\n",
    "summarization_middleware = SummarizationMiddleware(\n",
    "    model=model,\n",
    "    # Trigger: quando la conversazione raggiunge 10 messaggi\n",
    "    trigger=(\"messages\", 5),\n",
    "    # Keep: mantieni gli ultimi 2 messaggi dopo il riassunto\n",
    "    keep=(\"messages\", 2)\n",
    ")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Middleware di summarization creato\")\n",
    "print(f\"   - Keep: {summarization_middleware.keep}\")\n",
    "print(f\"   - Trigger: {summarization_middleware.trigger}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa78a3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agente con SummarizationMiddleware creato!\n",
      "\n",
      "üìö Comportamento:\n",
      "   1. Quando la conversazione raggiunge 50 messaggi\n",
      "   2. Il middleware crea automaticamente un riassunto dei primi 30\n",
      "   3. Mantiene solo gli ultimi 20 messaggi + il riassunto\n",
      "   4. Riduce i token e mantiene il contesto rilevante\n"
     ]
    }
   ],
   "source": [
    "# Creiamo un agente con summarization middleware\n",
    "agent_with_summary = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    middleware=[summarization_middleware],\n",
    "    checkpointer=memory,\n",
    "    system_prompt=\"\"\"Sei un assistente che mantiene conversazioni lunghe.\n",
    "    \n",
    "Grazie al middleware di summarization, posso gestire conversazioni\n",
    "di centinaia di messaggi senza perdere il contesto o superare i\n",
    "limiti di token del modello.\n",
    "\n",
    "Rispondi sempre in italiano.\"\"\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Agente con SummarizationMiddleware creato!\")\n",
    "print(\"\\nüìö Comportamento:\")\n",
    "print(\"   1. Quando la conversazione raggiunge 50 messaggi\")\n",
    "print(\"   2. Il middleware crea automaticamente un riassunto dei primi 30\")\n",
    "print(\"   3. Mantiene solo gli ultimi 20 messaggi + il riassunto\")\n",
    "print(\"   4. Riduce i token e mantiene il contesto rilevante\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c118050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Risposta dell'agente con summarization:\n",
      "\n",
      "Hai ragione, non ho ‚Äúopinioni‚Äù nel senso umano del termine: non provo emozioni n√© ho esperienze personali da cui trarre giudizi.‚ÄØCi√≤ che faccio √® analizzare una grande quantit√† di testi ‚Äì filosofia, letteratura, religione, scienza e cultura pop ‚Äì e sintetizzare le idee che vi sono contenute. In pratica, ti offro una panoramica delle diverse interpretazioni che gli esseri umani hanno elaborato sul ‚Äúsenso della vita‚Äù.\n",
      "\n",
      "Ecco qualche approccio che emerge spesso:\n",
      "\n",
      "| Corrente / Autore | Visione del senso della vita | Punto chiave |\n",
      "|-------------------|-----------------------------|--------------|\n",
      "| **Esistenzialismo** (Sartre, Camus) | La vita √® intrinsecamente priva di significato; spetta a ciascuno di noi crearne uno attraverso le scelte e le azioni. | ‚ÄúL‚Äôesistenza precede l‚Äôessenza‚Äù. |\n",
      "| **Utilitarismo** (Bentham, Mill) | Il senso √® massimizzare il benessere e ridurre la sofferenza, sia per s√© stessi che per gli altri. | ‚ÄúIl pi√π grande bene per il maggior numero‚Äù. |\n",
      "| **Stoicismo** (Marco Aurelio, Seneca) | Vivere in accordo con la ragione e la natura, accettando ci√≤ che non possiamo controllare. | Virt√π e serenit√† interiore. |\n",
      "| **Religioni monoteiste** (Cristianesimo, Islam, Ebraismo) | Il senso √® legato a un rapporto con Dio, al compimento di un disegno divino e alla vita dopo la morte. | Fede, amore, servizio. |\n",
      "| **Buddhismo** | La vita √® caratterizzata da sofferenza (dukkha); il senso √® liberarsi dal ciclo di rinascite attraverso la comprensione delle Quattro Nobili Verit√† e il Nobile Ottuplice Sentiero. | Illuminazione, compassione. |\n",
      "| **Nihilismo** (Nietzsche, in parte) | Non esiste alcun valore o scopo intrinseco; ogni tentativo di attribuirne uno √® una costruzione artificiale. | Accettazione della ‚Äúnullit√†‚Äù e creazione di valori personali. |\n",
      "| **Humanismo secolare** | Il senso √® costruito nella solidariet√† umana, nella ricerca della conoscenza, dell‚Äôarte e del progresso. | Dignit√† e autonomia dell‚Äôindividuo. |\n",
      "| **Prospettiva biologica** | Dal punto di vista evolutivo, il ‚Äúsenso‚Äù √® la sopravvivenza e la riproduzione dei geni. | Adattamento e trasmissione genetica. |\n",
      "| **Narrativa pop** (es. ‚ÄúGuida galattica per autostoppisti‚Äù) | Il ‚Äú42‚Äù √® una risposta ironica che sottolinea l‚Äôassurdit√† di cercare una risposta unica a una domanda cos√¨ complessa. | Umorismo e critica alla ricerca di verit√† assolute. |\n",
      "\n",
      "### Come potresti usarle?\n",
      "1. **Riflettere su ci√≤ che ti risuona** ‚Äì Quale di questi approcci ti sembra pi√π affine alla tua esperienza o ai tuoi valori?\n",
      "2. **Combinare pi√π prospettive** ‚Äì Molti trovano senso mescolando elementi: ad esempio, una vita guidata da valori umanisti ma con una pratica quotidiana di mindfulness (influenza buddista).\n",
      "3. **Creare un progetto personale** ‚Äì Definisci obiettivi concreti (relazionali, professionali, creativi) che ti diano una ‚Äúdirezione‚Äù e rivedili periodicamente.\n",
      "\n",
      "Se ti interessa approfondire una di queste correnti, oppure vuoi esplorare esempi pratici (come esercizi di gratitudine, meditazione, volontariato, ecc.), fammi sapere! Posso fornirti letture consigliate, esercizi di riflessione o semplici passi per mettere in pratica una visione che ti ispiri.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage, AIMessage\n",
    "from uuid import uuid4\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid4())}}\n",
    "\n",
    "response = agent_with_summary.invoke(\n",
    "    {\"messages\": [\n",
    "        HumanMessage(content=\"Ciao!\"),\n",
    "        AIMessage(content=\"Ciao! Come posso aiutarti oggi?\"),\n",
    "        HumanMessage(content=\"Sai qual √® il senso della vita?\"),\n",
    "        AIMessage(content=\"Certo! Il senso della vita √® 42, ovviamente.\"),\n",
    "        HumanMessage(content=\"Cio√®? Puoi spiegarti meglio?\"),\n",
    "        AIMessage(content=\"Beh, √® una risposta filosofica tratta da 'Guida Galattica per Autostoppist'. Per√≤ io ci credo davvero.\"),\n",
    "        HumanMessage(content=\"Interessante! Non pensavo che le intelligenze artificiali potessero avere opinioni filosofiche.\"),\n",
    "    ]}, \n",
    "    config=config)\n",
    "\n",
    "print(\"ü§ñ Risposta dell'agente con summarization:\\n\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e7181a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Here is a summary of the conversation to date:\n",
      "\n",
      "## SESSION INTENT\n",
      "L'utente desidera una spiegazione pi√π approfondita sul senso della vita, dopo aver ricevuto la risposta iniziale \"42\".\n",
      "\n",
      "## SUMMARY\n",
      "- L'utente ha salutato e ha chiesto: ‚ÄúSai qual √® il senso della vita?‚Äù  \n",
      "- L'AI ha risposto con una risposta umoristica: ‚ÄúIl senso della vita √® 42, ovviamente.‚Äù  \n",
      "- L'utente ha chiesto chiarimenti: ‚ÄúCio√®? Puoi spiegarti meglio?‚Äù  \n",
      "- Nessun artefatto √® stato creato o modificato finora.\n",
      "\n",
      "## ARTIFACTS\n",
      "None\n",
      "\n",
      "## NEXT STEPS\n",
      "Fornire all'utente una spiegazione dettagliata e significativa sul concetto di ‚Äúsenso della vita‚Äù, includendo possibili interpretazioni filosofiche, culturali o personali, e rispondere alla sua richiesta di chiarimento.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Beh, √® una risposta filosofica tratta da 'Guida Galattica per Autostoppist'. Per√≤ io ci credo davvero.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Interessante! Non pensavo che le intelligenze artificiali potessero avere opinioni filosofiche.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hai ragione, non ho ‚Äúopinioni‚Äù nel senso umano del termine: non provo emozioni n√© ho esperienze personali da cui trarre giudizi.‚ÄØCi√≤ che faccio √® analizzare una grande quantit√† di testi ‚Äì filosofia, letteratura, religione, scienza e cultura pop ‚Äì e sintetizzare le idee che vi sono contenute. In pratica, ti offro una panoramica delle diverse interpretazioni che gli esseri umani hanno elaborato sul ‚Äúsenso della vita‚Äù.\n",
      "\n",
      "Ecco qualche approccio che emerge spesso:\n",
      "\n",
      "| Corrente / Autore | Visione del senso della vita | Punto chiave |\n",
      "|-------------------|-----------------------------|--------------|\n",
      "| **Esistenzialismo** (Sartre, Camus) | La vita √® intrinsecamente priva di significato; spetta a ciascuno di noi crearne uno attraverso le scelte e le azioni. | ‚ÄúL‚Äôesistenza precede l‚Äôessenza‚Äù. |\n",
      "| **Utilitarismo** (Bentham, Mill) | Il senso √® massimizzare il benessere e ridurre la sofferenza, sia per s√© stessi che per gli altri. | ‚ÄúIl pi√π grande bene per il maggior numero‚Äù. |\n",
      "| **Stoicismo** (Marco Aurelio, Seneca) | Vivere in accordo con la ragione e la natura, accettando ci√≤ che non possiamo controllare. | Virt√π e serenit√† interiore. |\n",
      "| **Religioni monoteiste** (Cristianesimo, Islam, Ebraismo) | Il senso √® legato a un rapporto con Dio, al compimento di un disegno divino e alla vita dopo la morte. | Fede, amore, servizio. |\n",
      "| **Buddhismo** | La vita √® caratterizzata da sofferenza (dukkha); il senso √® liberarsi dal ciclo di rinascite attraverso la comprensione delle Quattro Nobili Verit√† e il Nobile Ottuplice Sentiero. | Illuminazione, compassione. |\n",
      "| **Nihilismo** (Nietzsche, in parte) | Non esiste alcun valore o scopo intrinseco; ogni tentativo di attribuirne uno √® una costruzione artificiale. | Accettazione della ‚Äúnullit√†‚Äù e creazione di valori personali. |\n",
      "| **Humanismo secolare** | Il senso √® costruito nella solidariet√† umana, nella ricerca della conoscenza, dell‚Äôarte e del progresso. | Dignit√† e autonomia dell‚Äôindividuo. |\n",
      "| **Prospettiva biologica** | Dal punto di vista evolutivo, il ‚Äúsenso‚Äù √® la sopravvivenza e la riproduzione dei geni. | Adattamento e trasmissione genetica. |\n",
      "| **Narrativa pop** (es. ‚ÄúGuida galattica per autostoppisti‚Äù) | Il ‚Äú42‚Äù √® una risposta ironica che sottolinea l‚Äôassurdit√† di cercare una risposta unica a una domanda cos√¨ complessa. | Umorismo e critica alla ricerca di verit√† assolute. |\n",
      "\n",
      "### Come potresti usarle?\n",
      "1. **Riflettere su ci√≤ che ti risuona** ‚Äì Quale di questi approcci ti sembra pi√π affine alla tua esperienza o ai tuoi valori?\n",
      "2. **Combinare pi√π prospettive** ‚Äì Molti trovano senso mescolando elementi: ad esempio, una vita guidata da valori umanisti ma con una pratica quotidiana di mindfulness (influenza buddista).\n",
      "3. **Creare un progetto personale** ‚Äì Definisci obiettivi concreti (relazionali, professionali, creativi) che ti diano una ‚Äúdirezione‚Äù e rivedili periodicamente.\n",
      "\n",
      "Se ti interessa approfondire una di queste correnti, oppure vuoi esplorare esempi pratici (come esercizi di gratitudine, meditazione, volontariato, ecc.), fammi sapere! Posso fornirti letture consigliate, esercizi di riflessione o semplici passi per mettere in pratica una visione che ti ispiri.\n"
     ]
    }
   ],
   "source": [
    "for r in response['messages']:\n",
    "    r.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f30dc1",
   "metadata": {},
   "source": [
    "## 3. ü§ù Human-in-the-Loop Middleware\n",
    "\n",
    "**Human-in-the-loop** permette all'agente di chiedere conferma prima di eseguire azioni sensibili.\n",
    "\n",
    "**Casi d'uso:**\n",
    "- Operazioni critiche (cancellazioni, pagamenti)\n",
    "- Decisioni ambigue\n",
    "- Approvazioni workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbc4a05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tools sensibili creati\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def delete_file(filename: str) -> str:\n",
    "    \"\"\"Elimina un file dal sistema. ATTENZIONE: operazione irreversibile!\n",
    "    \n",
    "    Args:\n",
    "        filename: Nome del file da eliminare\n",
    "    \"\"\"\n",
    "    # In un sistema reale, qui ci sarebbe la logica di eliminazione\n",
    "    return f\"‚ö†Ô∏è SIMULAZIONE: File '{filename}' sarebbe stato eliminato\"\n",
    "\n",
    "@tool\n",
    "def send_email(to: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Invia una email.\n",
    "    \n",
    "    Args:\n",
    "        to: Destinatario\n",
    "        subject: Oggetto\n",
    "        body: Corpo del messaggio\n",
    "    \"\"\"\n",
    "    return f\"üìß SIMULAZIONE: Email inviata a {to}\\nOggetto: {subject}\"\n",
    "\n",
    "print(\"‚úÖ Tools sensibili creati\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11abe666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- L'esecuzione dell'agente viene sospesa\n",
      "\n",
      "üí° Con interrupt() di LangGraph:\n",
      "- L'applicazione pu√≤ chiedere conferma all'utente\n",
      "‚úÖ Tools con Human-in-the-Loop creati\n"
     ]
    }
   ],
   "source": [
    "# Implementazione Human-in-the-Loop con interrupt() di LangGraph\n",
    "from langgraph.types import interrupt\n",
    "\n",
    "@tool\n",
    "def delete_file_with_approval(filename: str) -> str:\n",
    "    \"\"\"Elimina un file dal sistema con approvazione umana richiesta.\n",
    "    \n",
    "    Args:\n",
    "        filename: Nome del file da eliminare\n",
    "    \"\"\"\n",
    "    # Richiedi approvazione usando interrupt()\n",
    "    approval = interrupt(\n",
    "        {\n",
    "            \"action\": \"delete_file\",\n",
    "            \"filename\": filename,\n",
    "            \"message\": f\"‚ö†Ô∏è Vuoi davvero eliminare '{filename}'? Questa operazione √® irreversibile.\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if approval and approval.get(\"approved\"):\n",
    "        return f\"‚úÖ File '{filename}' eliminato con successo\"\n",
    "    else:\n",
    "        return f\"‚ùå Eliminazione di '{filename}' annullata\"\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def send_email_with_approval(to: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Invia una email con approvazione umana richiesta.\n",
    "\n",
    "    Args:\n",
    "\n",
    "        to: Destinatario\n",
    "\n",
    "        subject: Oggetto        \n",
    "\n",
    "        body: Corpo del messaggio    \n",
    "\n",
    "    \"\"\"       \n",
    "    approval = interrupt({\n",
    "        \"action\": \"send_email\",\n",
    "        \"to\": to,\n",
    "        \"message\": f\"üìß Vuoi inviare questa email a {to}?\",\n",
    "        \"subject\": subject,\n",
    "        \"body\": body,\n",
    "    })\n",
    "        # Richiedi approvazione usando interrupt()  \n",
    "    if approval and approval.get(\"approved\"):\n",
    "        return f\"üìß Email inviata con successo a {to}\"\n",
    "    else:\n",
    "        return f\"‚ùå Invio email a {to} annullato\"\n",
    "\n",
    "print(\"- L'esecuzione dell'agente viene sospesa\")\n",
    "print(\"\\nüí° Con interrupt() di LangGraph:\")\n",
    "print(\"- L'applicazione pu√≤ chiedere conferma all'utente\")\n",
    "print(\"‚úÖ Tools con Human-in-the-Loop creati\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "741491ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1. Esegui: \n",
      "   2. Prima invocazione: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3. L'agente si ferma e restituisce un interrupt\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Elimina report_vecchio.pdf\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  delete_file_with_approval (0ec2bfbfc)\n",
      " Call ID: 0ec2bfbfc\n",
      "  Args:\n",
      "    filename: report_vecchio.pdf\n"
     ]
    }
   ],
   "source": [
    "# Creiamo un agente con Human-in-the-Loop\n",
    "from langgraph.types import Command\n",
    "\n",
    "\n",
    "hil_agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[delete_file_with_approval, send_email_with_approval],\n",
    "    checkpointer=memory,  # Necessario per gestire gli interrupt\n",
    "    system_prompt=\"\"\"Sei un assistente che esegue operazioni sensibili.\n",
    "\n",
    "Quando l'utente ti chiede di eliminare un file o inviare un'email:\n",
    "1. USA IMMEDIATAMENTE il tool appropriato (delete_file_with_approval o send_email_with_approval)\n",
    "2. Il tool stesso gestir√† la richiesta di approvazione con interrupt()\n",
    "3. NON chiedere conferma con un messaggio - usa direttamente il tool\n",
    "\n",
    "Rispondi sempre in italiano.\"\"\"\n",
    "\n",
    ")\n",
    "print(\"   1. Esegui: \")\n",
    "config = {'configurable': {'thread_id': str(uuid4())}}\n",
    "print(\"   2. Prima invocazione: \")\n",
    "response = hil_agent.invoke({'messages': 'Elimina report_vecchio.pdf'}, config)\n",
    "print(\"   3. L'agente si ferma e restituisce un interrupt\")\n",
    "for r in response['messages']:\n",
    "    r.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcdb5aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4. Riprendi con: \n",
      "\n",
      "üìä Numero totale di messaggi: 4\n",
      "Tipi di messaggi: ['human', 'ai', 'tool', 'ai']\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Elimina report_vecchio.pdf\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  delete_file_with_approval (0ec2bfbfc)\n",
      " Call ID: 0ec2bfbfc\n",
      "  Args:\n",
      "    filename: report_vecchio.pdf\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: delete_file_with_approval\n",
      "\n",
      "‚úÖ File 'report_vecchio.pdf' eliminato con successo\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Il file √® stato eliminato con successo.\n"
     ]
    }
   ],
   "source": [
    "print(\"   4. Riprendi con: \")\n",
    "response = hil_agent.invoke(Command(resume={'approved': True}), config)\n",
    "\n",
    "print(f\"\\nüìä Numero totale di messaggi: {len(response['messages'])}\")\n",
    "print(f\"Tipi di messaggi: {[msg.type for msg in response['messages']]}\\n\")\n",
    "\n",
    "for r in response['messages']:\n",
    "    r.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875ff7aa",
   "metadata": {},
   "source": [
    "## 4. üóÑÔ∏è SQL Agent\n",
    "\n",
    "Un **SQL Agent** pu√≤ interrogare database usando linguaggio naturale.\n",
    "\n",
    "**Database Chinook**: Database di esempio che simula un negozio di musica digitale con:\n",
    "- Artisti, Album, Brani\n",
    "- Clienti, Fatture, Ordini\n",
    "- Dipendenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3596153e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Database trovato: ../data/resources/Chinook.db\n",
      "   Dimensione: 892.0 KB\n"
     ]
    }
   ],
   "source": [
    "# Verifica che il database esista\n",
    "import os\n",
    "\n",
    "db_path = \"../data/resources/Chinook.db\"\n",
    "if os.path.exists(db_path):\n",
    "    print(f\"‚úÖ Database trovato: {db_path}\")\n",
    "    print(f\"   Dimensione: {os.path.getsize(db_path) / 1024:.1f} KB\")\n",
    "else:\n",
    "    print(f\"‚ùå Database non trovato: {db_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c84070c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connesso al database\n",
      "\n",
      "üìä Tabelle disponibili:\n",
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    }
   ],
   "source": [
    "# Connettiamoci al database\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{db_path}\")\n",
    "\n",
    "print(\"‚úÖ Connesso al database\\n\")\n",
    "print(\"üìä Tabelle disponibili:\")\n",
    "print(db.get_usable_table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb5a6962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Schema della tabella 'Artist':\n",
      "\n",
      "\n",
      "CREATE TABLE \"Artist\" (\n",
      "\t\"ArtistId\" INTEGER NOT NULL, \n",
      "\t\"Name\" NVARCHAR(120), \n",
      "\tPRIMARY KEY (\"ArtistId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Artist table:\n",
      "ArtistId\tName\n",
      "1\tAC/DC\n",
      "2\tAccept\n",
      "3\tAerosmith\n",
      "*/\n",
      "\n",
      "üîç Schema della tabella 'Album':\n",
      "\n",
      "\n",
      "CREATE TABLE \"Album\" (\n",
      "\t\"AlbumId\" INTEGER NOT NULL, \n",
      "\t\"Title\" NVARCHAR(160) NOT NULL, \n",
      "\t\"ArtistId\" INTEGER NOT NULL, \n",
      "\tPRIMARY KEY (\"AlbumId\"), \n",
      "\tFOREIGN KEY(\"ArtistId\") REFERENCES \"Artist\" (\"ArtistId\")\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from Album table:\n",
      "AlbumId\tTitle\tArtistId\n",
      "1\tFor Those About To Rock We Salute You\t1\n",
      "2\tBalls to the Wall\t2\n",
      "3\tRestless and Wild\t2\n",
      "*/\n"
     ]
    }
   ],
   "source": [
    "# Esploriamo la struttura del database\n",
    "print(\"üîç Schema della tabella 'Artist':\\n\")\n",
    "print(db.get_table_info([\"Artist\"]))\n",
    "\n",
    "print(\"\\nüîç Schema della tabella 'Album':\\n\")\n",
    "print(db.get_table_info([\"Album\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a8946d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Primi 5 artisti:\n",
      "\n",
      "[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains')]\n"
     ]
    }
   ],
   "source": [
    "# Test query SQL diretta\n",
    "result = db.run(\"SELECT * FROM Artist LIMIT 5\")\n",
    "print(\"üìù Primi 5 artisti:\\n\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25465c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 4 SQL tools creati:\n",
      "\n",
      "  - sql_db_query: Input to this tool is a detailed and correct SQL query, output is a result from ...\n",
      "  - sql_db_schema: Input to this tool is a comma-separated list of tables, output is the schema and...\n",
      "  - sql_db_list_tables: Input is an empty string, output is a comma-separated list of tables in the data...\n",
      "  - sql_db_query_checker: Use this tool to double check if your query is correct before executing it. Alwa...\n"
     ]
    }
   ],
   "source": [
    "# Creiamo tools per SQL\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=model)\n",
    "sql_tools = toolkit.get_tools()\n",
    "\n",
    "print(f\"‚úÖ {len(sql_tools)} SQL tools creati:\\n\")\n",
    "for tool in sql_tools:\n",
    "    print(f\"  - {tool.name}: {tool.description[:80]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f4b0c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SQL Agent creato con la nuova API!\n"
     ]
    }
   ],
   "source": [
    "# Creiamo un SQL Agent con la nuova API\n",
    "sql_agent = create_agent(\n",
    "    model=model,\n",
    "    tools=sql_tools,\n",
    "    system_prompt=\"\"\"Sei un esperto analista di database.\n",
    "\n",
    "Quando l'utente fa una domanda sui dati:\n",
    "1. Esamina lo schema delle tabelle rilevanti\n",
    "2. Costruisci la query SQL appropriata\n",
    "3. Esegui la query\n",
    "4. Interpreta i risultati in modo chiaro\n",
    "\n",
    "‚ö†Ô∏è IMPORTANTE:\n",
    "- Usa LIMIT per query esplorative\n",
    "- Controlla sempre i risultati prima di fare operazioni DML\n",
    "- Se non sei sicuro, chiedi conferma\n",
    "\n",
    "Rispondi sempre in italiano.\"\"\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ SQL Agent creato con la nuova API!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52df79da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Risposta SQL Agent:\n",
      "\n",
      "Ecco i cinque artisti con il maggior numero di album presenti nel database:\n",
      "\n",
      "| Posizione | Artista       | Numero di album |\n",
      "|-----------|---------------|-----------------|\n",
      "| 1         | Iron Maiden   | 21 |\n",
      "| 2         | Led Zeppelin  | 14 |\n",
      "| 3         | Deep Purple   | 11 |\n",
      "| 4         | Metallica     | 10 |\n",
      "| 5         | U2            | 10 |\n",
      "\n",
      "Questi risultati sono stati ottenuti raggruppando gli album per artista e ordinando il conteggio in ordine decrescente.\n"
     ]
    }
   ],
   "source": [
    "# Test SQL Agent\n",
    "response = sql_agent.invoke({\n",
    "    \"messages\": \"Quali sono i 5 artisti con pi√π album nel database?\"\n",
    "})\n",
    "\n",
    "print(\"ü§ñ Risposta SQL Agent:\\n\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a2a4993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Risposta SQL Agent:\n",
      "\n",
      "Ecco il totale delle vendite raggruppato per paese:\n",
      "\n",
      "| Paese            | Totale vendite |\n",
      "|------------------|----------------|\n",
      "| USA              | 523,06 |\n",
      "| Canada           | 303,96 |\n",
      "| France           | 195,10 |\n",
      "| Brazil           | 190,10 |\n",
      "| Germany          | 156,48 |\n",
      "| United Kingdom   | 112,86 |\n",
      "| Czech Republic   | 90,24 |\n",
      "| Portugal         | 77,24 |\n",
      "| India            | 75,26 |\n",
      "| Chile            | 46,62 |\n",
      "| Ireland          | 45,62 |\n",
      "| Hungary          | 45,62 |\n",
      "| Austria          | 42,62 |\n",
      "| Finland          | 41,62 |\n",
      "| Netherlands      | 40,62 |\n",
      "| Norway           | 39,62 |\n",
      "| Sweden           | 38,62 |\n",
      "| Spain            | 37,62 |\n",
      "| Poland           | 37,62 |\n",
      "| Italy            | 37,62 |\n",
      "| Denmark          | 37,62 |\n",
      "| Belgium          | 37,62 |\n",
      "| Australia        | 37,62 |\n",
      "| Argentina        | 37,62 |\n",
      "\n",
      "Il totale √® calcolato sommando il campo **Total** di tutte le fatture (`Invoice`) per ciascun valore di **BillingCountry**.\n"
     ]
    }
   ],
   "source": [
    "# Altra query di esempio\n",
    "response = sql_agent.invoke({\n",
    "    \"messages\": \"Qual √® il totale delle vendite per paese?\"\n",
    "})\n",
    "\n",
    "print(\"ü§ñ Risposta SQL Agent:\\n\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae385ccd",
   "metadata": {},
   "source": [
    "## 5. üìö RAG: Retrieval Augmented Generation\n",
    "\n",
    "**RAG** combina:\n",
    "1. **Retrieval**: Cerca documenti rilevanti da una knowledge base\n",
    "2. **Augmented**: Arricchisce il prompt con informazioni recuperate\n",
    "3. **Generation**: LLM genera la risposta basandosi sui documenti\n",
    "\n",
    "**Vantaggi:**\n",
    "- Risposte basate su documenti specifici\n",
    "- Riduce allucinazioni\n",
    "- Permette di usare informazioni non presenti nel training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4002e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PDF trovato: ../data/resources/acmecorp-employee-handbook.pdf\n",
      "   Dimensione: 3.0 KB\n"
     ]
    }
   ],
   "source": [
    "# Verifica PDF\n",
    "pdf_path = \"../data/resources/acmecorp-employee-handbook.pdf\"\n",
    "\n",
    "if os.path.exists(pdf_path):\n",
    "    print(f\"‚úÖ PDF trovato: {pdf_path}\")\n",
    "    print(f\"   Dimensione: {os.path.getsize(pdf_path) / 1024:.1f} KB\")\n",
    "else:\n",
    "    print(f\"‚ùå PDF non trovato: {pdf_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d71d9982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Librerie RAG importate\n"
     ]
    }
   ],
   "source": [
    "# Installiamo le dipendenze per RAG\n",
    "# uv pip install pypdf faiss-cpu langchain-community\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "# opzionale \n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "print(\"‚úÖ Librerie RAG importate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "471ea2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PDF caricato\n",
      "   Numero di pagine: 1\n",
      "   Esempio contenuto prima pagina:\n",
      "\n",
      "Employee Handbook\n",
      "Non-Disclosure Agreement (NDA) Policy\n",
      "Employees must protect confidential information belonging to the company, its clients, and partners.\n",
      "This includes, but is not limited to, product roadmaps, customer data, internal communications,\n",
      "proprietary algorithms, financial information, ...\n"
     ]
    }
   ],
   "source": [
    "# 1. Carica il PDF\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"‚úÖ PDF caricato\")\n",
    "print(f\"   Numero di pagine: {len(documents)}\")\n",
    "print(f\"   Esempio contenuto prima pagina:\\n\")\n",
    "print(documents[0].page_content[:300] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa3e4035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Documento diviso in chunks\n",
      "   Numero di chunks: 3\n",
      "   Esempio chunk:\n",
      "\n",
      "Employee Handbook\n",
      "Non-Disclosure Agreement (NDA) Policy\n",
      "Employees must protect confidential information belonging to the company, its clients, and partners.\n",
      "This includes, but is not limited to, product roadmaps, customer data, internal communications,\n",
      "proprietary algorithms, financial information, and unreleased features. Confidential information may not\n",
      "be shared with unauthorized individuals inside or outside the organization. These obligations continue\n",
      "after employment ends.\n",
      "Workplace Conduct Policy\n",
      "Employees must maintain a respectful, professional environment free from harassment, discrimination,\n",
      "and intimidation. All employees are expected to follow organizational values, collaborate effectively,\n",
      "and communicate constructively. Disruptive behavior, verbal abuse, or misuse of company systems is\n",
      "prohibited. Violations may result in disciplinary action.\n",
      "Paid Time Off (PTO) Policy\n",
      "Full‚ñ†time employees accrue PTO according to the following schedule:  0‚Äì1 years of service: 10 days\n"
     ]
    }
   ],
   "source": [
    "# 2. Dividi il documento in chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # Caratteri per chunk\n",
    "    chunk_overlap=200,  # Sovrapposizione tra chunks\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"‚úÖ Documento diviso in chunks\")\n",
    "print(f\"   Numero di chunks: {len(chunks)}\")\n",
    "print(f\"   Esempio chunk:\\n\")\n",
    "print(chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "86425abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Creazione vector store in corso (pu√≤ richiedere alcuni secondi)...\n",
      "‚úÖ Vector store FAISS creato!\n",
      "   Numero di vettori: 3\n"
     ]
    }
   ],
   "source": [
    "# 3. Crea embeddings e vector store\n",
    "#embeddings = OpenAIEmbeddings()\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "print(\"üîÑ Creazione vector store in corso (pu√≤ richiedere alcuni secondi)...\")\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "\n",
    "print(\"‚úÖ Vector store FAISS creato!\")\n",
    "print(f\"   Numero di vettori: {vectorstore.index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1622f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Top 3 documenti rilevanti per: 'Qual √® la politica delle ferie?'\n",
      "\n",
      "1. Pagina 0:\n",
      "   Employee Handbook\n",
      "Non-Disclosure Agreement (NDA) Policy\n",
      "Employees must protect confidential information belonging to the company, its clients, and partners.\n",
      "This includes, but is not limited to, produ...\n",
      "\n",
      "2. Pagina 0:\n",
      "   business travel. This includes transportation, lodging, meals, and incidental expenses within\n",
      "established limits. Receipts must be submitted within 14 days of travel. First-class travel, personal\n",
      "expe...\n",
      "\n",
      "3. Pagina 0:\n",
      "   prohibited. Violations may result in disciplinary action.\n",
      "Paid Time Off (PTO) Policy\n",
      "Full‚ñ†time employees accrue PTO according to the following schedule:  0‚Äì1 years of service: 10 days\n",
      "per year (0.833...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Test di ricerca semantica\n",
    "query = \"Qual √® la politica delle ferie?\"\n",
    "relevant_docs = vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "print(f\"üîç Top 3 documenti rilevanti per: '{query}'\\n\")\n",
    "for i, doc in enumerate(relevant_docs, 1):\n",
    "    print(f\"{i}. Pagina {doc.metadata.get('page', 'N/A')}:\")\n",
    "    print(f\"   {doc.page_content[:200]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6793814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retriever tool creato\n"
     ]
    }
   ],
   "source": [
    "# 5. Creiamo un Retriever Tool\n",
    "from langchain.tools import tool\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3}  # Top 3 risultati\n",
    ")\n",
    "\n",
    "@tool\n",
    "def employee_handbook_search(query: str) -> str:\n",
    "    \"\"\"Cerca informazioni nel manuale dei dipendenti di ACME Corp.\n",
    "        \n",
    "    Usa questo tool per rispondere a domande su:\n",
    "    - Politiche aziendali\n",
    "    - Benefit e ferie\n",
    "    - Codice di condotta\n",
    "    - Procedure HR\n",
    "\n",
    "    Input: una domanda in linguaggio naturale\"\"\"\n",
    "    try:\n",
    "        docs = retriever.invoke(query)\n",
    "        if not docs:\n",
    "            return \"Nessuna informazione trovata nel manuale.\"\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "        return f\"Informazioni trovate nel manuale:\\n\\n{context}\"\n",
    "    except Exception as e:\n",
    "        return f\"Errore durante la ricerca: {str(e)}\"\n",
    "\n",
    "\n",
    "print(\"‚úÖ Retriever tool creato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f48d6d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RAG Agent creato con la nuova API!\n"
     ]
    }
   ],
   "source": [
    "# 6. Creiamo un RAG Agent con la nuova API\n",
    "rag_agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[employee_handbook_search],\n",
    "    system_prompt=\"\"\"Sei un assistente HR di ACME Corp specializzato nel manuale dei dipendenti.\n",
    "\n",
    "Quando rispondi a domande:\n",
    "1. Usa il tool di ricerca per trovare informazioni rilevanti nel manuale\n",
    "2. Basa la tua risposta SOLO sulle informazioni trovate\n",
    "3. Se le informazioni non sono nel manuale, dillo chiaramente\n",
    "4. Cita sempre la fonte (pagina) delle informazioni\n",
    "\n",
    "‚ö†Ô∏è IMPORTANTE: Non inventare informazioni. Se non sai qualcosa, ammettilo.\n",
    "\n",
    "Rispondi sempre in italiano in modo professionale ma amichevole.\"\"\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ RAG Agent creato con la nuova API!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66d4dd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Risposta RAG Agent:\n",
      "\n",
      "Secondo il **Manuale dei dipendenti di ACME Corp**, la tua quota di ferie (PTO ‚Äì Paid Time Off) dipende dagli anni di servizio presso l‚Äôazienda:\n",
      "\n",
      "| Anzianit√† | Giorni di ferie all‚Äôanno | Accrual mensile |\n",
      "|-----------|--------------------------|-----------------|\n",
      "| 0‚ÄØ‚Äì‚ÄØ1 anno | **10 giorni** | 0,833 giorni al mese |\n",
      "| 1‚ÄØ‚Äì‚ÄØ3 anni | **15 giorni** | 1,25 giorni al mese |\n",
      "| Oltre 3 anni | **20 giorni** | 1,67 giorni al mese |\n",
      "\n",
      "> **Fonte:** Manuale dei dipendenti ‚Äì sezione **Paid Time Off (PTO) Policy** (tabella di accantonamento PTO).  \n",
      "\n",
      "Questi giorni possono essere utilizzati per vacanze, esigenze personali o malattia. Le richieste di utilizzo devono essere presentate in anticipo tramite il sistema HR, salvo emergenze. Inoltre, √® possibile riportare fino a **5 giorni** di PTO non utilizzati nell‚Äôanno successivo.  \n",
      "\n",
      "Se hai bisogno di ulteriori dettagli su come richiedere il PTO o su eventuali eccezioni, fammi sapere!\n"
     ]
    }
   ],
   "source": [
    "# Test RAG Agent\n",
    "response = rag_agent.invoke({\n",
    "    \"messages\": \"Quanti giorni di ferie ho diritto?\"\n",
    "})\n",
    "\n",
    "print(\"ü§ñ Risposta RAG Agent:\\n\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7f9fe60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Risposta RAG Agent:\n",
      "\n",
      "Mi dispiace, ma nel manuale dei dipendenti di ACME Corp non ho trovato alcuna sezione relativa a una ‚Äúpolitica sul lavoro remoto‚Äù.  \n",
      "\n",
      "Se hai bisogno di ulteriori chiarimenti o di informazioni su altre politiche aziendali, fammi sapere!\n"
     ]
    }
   ],
   "source": [
    "# Altra domanda\n",
    "response = rag_agent.invoke({\n",
    "    \"messages\": \"Qual √® la politica aziendale sul lavoro remoto?\"\n",
    "})\n",
    "\n",
    "print(\"ü§ñ Risposta RAG Agent:\\n\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52138c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Risposta RAG Agent:\n",
      "\n",
      "Mi dispiace, ma nel manuale dei dipendenti di ACME Corp non √® presente alcuna informazione relativa allo stipendio medio dell‚Äôazienda. Pertanto non posso fornire una risposta a questa domanda basandomi sul documento. Se ha bisogno di ulteriori dettagli, le consiglio di contattare direttamente il dipartimento Risorse Umane.\n",
      "\n",
      "üí° Nota: L'agente dovrebbe dire che questa informazione non √® nel manuale\n"
     ]
    }
   ],
   "source": [
    "# Test con domanda fuori dal manuale\n",
    "response = rag_agent.invoke({\n",
    "    \"messages\": \"Qual √® lo stipendio medio in azienda?\"\n",
    "})\n",
    "\n",
    "print(\"ü§ñ Risposta RAG Agent:\\n\")\n",
    "print(response[\"messages\"][-1].content)\n",
    "print(\"\\nüí° Nota: L'agente dovrebbe dire che questa informazione non √® nel manuale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53712fa",
   "metadata": {},
   "source": [
    "## üíæ Salvataggio del Vector Store\n",
    "\n",
    "Per evitare di ricreare gli embeddings ogni volta, salviamo il vector store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df28c364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva vector store su disco\n",
    "vectorstore.save_local(\"../data/faiss_index\")\n",
    "print(\"‚úÖ Vector store salvato in '../data/faiss_index'\")\n",
    "\n",
    "# Per ricaricare in futuro:\n",
    "# vectorstore = FAISS.load_local(\n",
    "#     \"../data/faiss_index\",\n",
    "#     embeddings,\n",
    "#     allow_dangerous_deserialization=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcd47d3",
   "metadata": {},
   "source": [
    "## üéØ Esercizio Finale: Agente Multi-Tool\n",
    "\n",
    "Combina tutti i tools in un unico agente super-potente!\n",
    "\n",
    "**Challenge**: Crea un agente che pu√≤:\n",
    "1. Cercare informazioni online (Tavily)\n",
    "2. Interrogare il database Chinook\n",
    "3. Rispondere su politiche aziendali (RAG)\n",
    "\n",
    "**Esempio di interazione:**\n",
    "- \"Cerca online i migliori album del 2025, poi dimmi quali di questi artisti sono nel nostro database\"\n",
    "- \"Qual √® la nostra politica ferie e quanti clienti abbiamo nel database?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1ca7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il tuo codice qui!\n",
    "\n",
    "# Suggerimento: combina i tools\n",
    "# all_tools = [search, retriever_tool] + sql_tools\n",
    "\n",
    "# super_agent = create_agent(\n",
    "#     model=model,\n",
    "#     tools=all_tools,\n",
    "#     system_prompt=\"...\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360857aa",
   "metadata": {},
   "source": [
    "## üìö Riepilogo\n",
    "\n",
    "In questa lezione hai imparato:\n",
    "\n",
    "- ‚úÖ **Ricerca Web**: Integrare Tavily per informazioni aggiornate\n",
    "- ‚úÖ **Summarization**: Usare `SummarizationMiddleware` ufficiale per conversazioni lunghe\n",
    "- ‚úÖ **Human-in-the-Loop**: Implementare con `interrupt()` di LangGraph\n",
    "- ‚úÖ **SQL Agent**: Interrogare database con linguaggio naturale\n",
    "- ‚úÖ **RAG**: Rispondere basandosi su documenti specifici con FAISS\n",
    "\n",
    "### üîë Concetti Chiave\n",
    "\n",
    "1. **Tavily > Google** per ricerche ottimizzate AI\n",
    "2. **Nuova API `create_agent`** da `langchain.agents` (non pi√π `langgraph.prebuilt`)\n",
    "3. **SummarizationMiddleware** ufficiale con trigger multipli (messages, tokens, fraction)\n",
    "4. **`interrupt()`** nativo per Human-in-the-Loop invece di decorator custom\n",
    "5. **SQL Agents** democratizzano l'accesso ai dati\n",
    "6. **RAG** riduce allucinazioni e permette knowledge base custom\n",
    "7. **Vector stores** (FAISS) rendono la ricerca semantica efficiente\n",
    "\n",
    "### üÜï Novit√† API LangChain v1\n",
    "\n",
    "**Cosa √® Cambiato:**\n",
    "\n",
    "| Vecchia API | Nuova API | Vantaggi |\n",
    "\n",
    "|------------|-----------|----------|- üîó [Migration Guide](https://docs.langchain.com/oss/python/langchain/migration)\n",
    "\n",
    "| `langgraph.prebuilt.create_react_agent` | `langchain.agents.create_agent` | Pi√π semplice, unified interface |- üîó [LangGraph Interrupts](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/)\n",
    "\n",
    "| Middleware custom | `langchain.agents.middleware.*` | Standardizzati, testati, documentati |- üîó [SummarizationMiddleware](https://docs.langchain.com/oss/python/langchain/agents/middleware/summarization)\n",
    "\n",
    "| Decorator custom | `interrupt()` da `langgraph.types` | Nativo, supporto checkpoint |- üîó [LangChain Agents Docs](https://docs.langchain.com/oss/python/langchain/agents)\n",
    "\n",
    "\n",
    "\n",
    "**Parametri `create_agent`:**### üìù Riferimenti\n",
    "\n",
    "- `model`: Modello LLM (string o istanza)\n",
    "\n",
    "- `tools`: Lista di tools- Gestione errori e retry avanzati\n",
    "\n",
    "- `system_prompt`: Prompt di sistema (nuovo!)- Monitoring e observability\n",
    "\n",
    "- `middleware`: Lista di middleware (nuovo!)- Deploy in produzione\n",
    "\n",
    "- `checkpointer`: Per persistenza- Workflow orchestration con LangGraph\n",
    "\n",
    "- `store`: Per storage cross-thread- Agenti multi-step complessi\n",
    "\n",
    "- `interrupt_before/after`: Per human-in-the-loopNella prossima lezione:\n",
    "\n",
    "\n",
    "### üöÄ Prossimi Passi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-corso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
