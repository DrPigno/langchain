{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00fbeaba",
   "metadata": {},
   "source": [
    "# Lezione 1: Introduzione agli Agenti LangChain\n",
    "\n",
    "Benvenuti alla prima lezione del corso! In questo notebook imparerete:\n",
    "\n",
    "1. Come inizializzare un modello con `init_chat_model`\n",
    "2. Come creare un agente con `create_agent`\n",
    "3. Come configurare prompts e system prompts\n",
    "4. Come aggiungere tools agli agenti\n",
    "5. Come aggiungere memoria a breve termine (checkpointer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6b513c",
   "metadata": {},
   "source": [
    "## 1. Verifica Setup\n",
    "\n",
    "Prima di tutto, verifichiamo che tutto sia configurato correttamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4e4b54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.13.11 (main, Dec 17 2025, 21:09:15) [MSC v.1944 64 bit (AMD64)]\n",
      "‚úÖ LangChain version: 1.2.6\n",
      "‚úÖ LangGraph version: 1.0.6\n"
     ]
    }
   ],
   "source": [
    "# Importiamo le librerie necessarie\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "try:\n",
    "    import langchain\n",
    "    import langgraph\n",
    "    from importlib.metadata import version\n",
    "    print(f\"‚úÖ LangChain version: {langchain.__version__}\")\n",
    "    print(f\"‚úÖ LangGraph version: {version('langgraph')}\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Errore import: {e}\")\n",
    "    print(\"Esegui: uv sync\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a7c4f5",
   "metadata": {},
   "source": [
    "## 2. Caricamento API Keys\n",
    "\n",
    "Carichiamo le API keys dal file `.env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5d2cb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API key caricata correttamente\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carica le variabili d'ambiente dal file .env\n",
    "load_dotenv()\n",
    "\n",
    "# Verifica che la chiave sia stata caricata\n",
    "if os.getenv(\"OPENAI_API_KEY\") or os.getenv(\"CEREBRAS_API_KEY\"):\n",
    "    print(\"‚úÖ API key caricata correttamente\")\n",
    "else:\n",
    "    print(\"‚ùå API key non trovata. Assicurati di aver configurato il file .env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9656d00c",
   "metadata": {},
   "source": [
    "## 3. Inizializzare un Modello con `init_chat_model`\n",
    "\n",
    "`init_chat_model` √® il modo standard per inizializzare un modello di chat in LangChain.\n",
    "\n",
    "**Vantaggi:**\n",
    "- Interfaccia unificata per qualsiasi provider (OpenAI, Anthropic, Google, ecc.)\n",
    "- Facile cambiare provider senza modificare il codice\n",
    "- Configurazione semplificata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1686dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modello inizializzato\n",
      "Tipo: <class 'langchain_openai.chat_models.base.ChatOpenAI'>\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Inizializziamo il modello - sintassi semplice!\n",
    "# Formato: \"provider:model-name\"\n",
    "\n",
    "model = init_chat_model(\n",
    "    \"openai:gpt-3.5-turbo\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Modello inizializzato\")\n",
    "print(f\"Tipo: {type(model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "08621749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modello Cerebras inizializzato\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVA: Usare Cerebras (pi√π veloce ed economico)\n",
    "# Installiamo langchain-cerebras se non √® presente\n",
    "# uv add langchain-cerebras (nel terminale)\n",
    "\n",
    "# Ora possiamo usare Cerebras\n",
    "from langchain_cerebras import ChatCerebras\n",
    "model = ChatCerebras(model=\"gpt-oss-120b\", temperature=0.7)\n",
    "print(\"‚úÖ Modello Cerebras inizializzato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b2d39a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un agente AI √® un software autonomo che percepisce l‚Äôambiente, elabora informazioni e compie azioni per raggiungere obiettivi definiti.\n"
     ]
    }
   ],
   "source": [
    "# Test rapido del modello\n",
    "response = model.invoke(\"Ciao! In una frase, spiegami cos'√® un agente AI.\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0cf3f937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 82,\n",
       " 'output_tokens': 85,\n",
       " 'total_tokens': 167,\n",
       " 'input_token_details': {'cache_read': 0},\n",
       " 'output_token_details': {}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "16a289ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Un agente AI √® un software autonomo che percepisce l‚Äôambiente, elabora informazioni e compie azioni per raggiungere obiettivi definiti.\n"
     ]
    }
   ],
   "source": [
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ea11af",
   "metadata": {},
   "source": [
    "### Cambiare Provider √® Facile!\n",
    "\n",
    "Per usare un altro modello, basta cambiare la stringa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e074871e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puoi cambiare provider semplicemente modificando la stringa del modello!\n"
     ]
    }
   ],
   "source": [
    "# Esempi di altri provider (commentati)\n",
    "\n",
    "# Anthropic Claude\n",
    "# model = init_chat_model(\"anthropic:claude-3-5-sonnet-20241022\", temperature=0.7)\n",
    "\n",
    "# Google Gemini  \n",
    "# model = init_chat_model(\"google_genai:gemini-2.5-flash-lite\", temperature=0.7)\n",
    "\n",
    "# Groq (veloce!)\n",
    "# model = init_chat_model(\"groq:llama-3.1-70b-versatile\", temperature=0.7)\n",
    "\n",
    "print(\"Puoi cambiare provider semplicemente modificando la stringa del modello!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea732c3",
   "metadata": {},
   "source": [
    "## 4. Creare un Agente Semplice con `create_agent`\n",
    "\n",
    "`create_agent` √® la nuova API semplificata per creare agenti in LangChain.\n",
    "\n",
    "**Caratteristiche:**\n",
    "- Costruito sopra LangGraph per robustezza\n",
    "- API semplice per casi d'uso comuni\n",
    "- Supporta tools, system prompts e memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e50ba952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# Creiamo un agente semplice SENZA tools\n",
    "simple_agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=\"Sei un assistente utile che risponde sempre in italiano in modo conciso.\"\n",
    ")\n",
    "\n",
    "#print(\"‚úÖ Agente semplice creato!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ec5e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agente: Certo! Nella *Guida galattica per gli autostoppisti* di Douglas Adams, ‚Äú42‚Äù √® la risposta fornita da un super‚Äëcomputer a ‚Äúla domanda fondamentale sulla vita, l‚Äôuniverso e tutto quanto‚Äù. √à un modo ironico per dire che la risposta definitiva √® forse fuori dalla nostra comprensione o che la ricerca stessa del significato √® pi√π importante della risposta.  \n",
      "\n",
      "In filosofia, vari pensatori hanno proposto diversi ‚Äúsensi‚Äù della vita:  \n",
      "\n",
      "* **Esistenzialismo** ‚Äì il significato √® creato da ciascuno di noi attraverso le proprie scelte.  \n",
      "* **Utilitarismo** ‚Äì massimizzare il benessere e la felicit√†.  \n",
      "* **Religioni** ‚Äì spesso legano il senso a un disegno divino o a una vita dopo la morte.  \n",
      "* **Stoicismo** ‚Äì vivere in accordo con la ragione e accettare ci√≤ che non possiamo controllare.  \n",
      "\n",
      "Quindi, ‚Äú42‚Äù √® un promemoria: il vero ‚Äúsenso‚Äù potrebbe non essere un numero o una risposta unica, ma la nostra capacit√† di dare significato alle nostre esperienze.\n"
     ]
    }
   ],
   "source": [
    "# Testiamo l'agente semplice\n",
    "response = simple_agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Ciao! Chi sei?\"}]\n",
    "})\n",
    "\n",
    "print(\"Agente:\", response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7186db",
   "metadata": {},
   "source": [
    "## 5. System Prompt e Tecniche di Prompting\n",
    "\n",
    "I **system prompt** sono fondamentali per guidare il comportamento dell'LLM. Vediamo tecniche avanzate per ottenere risultati migliori."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64a2c3e",
   "metadata": {},
   "source": [
    "### üìù Tecnica 1: Few-Shot Examples\n",
    "\n",
    "Il **few-shot prompting** consiste nel fornire esempi al modello per guidarlo verso il formato/stile desiderato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a5971df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ System prompt con few-shot examples creato\n",
      "\n",
      "üìù Contenuto del system prompt:\n",
      "Sei un esperto di geografia. Rispondi seguendo il formato degli esempi forniti.\n",
      "\n",
      "Esempi:\n",
      "\n",
      "Utente: Parigi\n",
      "Assistente: üá´üá∑ Parigi √® la capitale della Francia. Popolazione: ~2.2M abitanti. Famosa per: Torre Eiffel, Louvre, Notre-Dame.\n",
      "\n",
      "Utente: Tokyo\n",
      "Assistente: üáØüáµ Tokyo √® la capitale del Giappone. Popolazione: ~14M abitanti. Famosa per: Monte Fuji, Shibuya, templi antichi.\n",
      "\n",
      "Utente: Roma\n",
      "Assistente: üáÆüáπ Roma √® la capitale dell'Italia. Popolazione: ~2.8M abitanti. Famosa per: Colosseo, Vaticano, Fontana di Trevi.\n",
      "\n",
      "Ora rispondi tu seguendo lo stesso stile e formato!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creiamo un system prompt con few-shot examples\n",
    "# Questo pu√≤ essere usato direttamente con create_agent()\n",
    "\n",
    "system_prompt = \"\"\"Sei un esperto di geografia. Rispondi seguendo il formato degli esempi forniti.\n",
    "\n",
    "Esempi:\n",
    "\n",
    "Utente: Parigi\n",
    "Assistente: üá´üá∑ Parigi √® la capitale della Francia. Popolazione: ~2.2M abitanti. Famosa per: Torre Eiffel, Louvre, Notre-Dame.\n",
    "\n",
    "Utente: Tokyo\n",
    "Assistente: üáØüáµ Tokyo √® la capitale del Giappone. Popolazione: ~14M abitanti. Famosa per: Monte Fuji, Shibuya, templi antichi.\n",
    "\n",
    "Utente: Roma\n",
    "Assistente: üáÆüáπ Roma √® la capitale dell'Italia. Popolazione: ~2.8M abitanti. Famosa per: Colosseo, Vaticano, Fontana di Trevi.\n",
    "\n",
    "Ora rispondi tu seguendo lo stesso stile e formato!\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚úÖ System prompt con few-shot examples creato\")\n",
    "print(\"\\nüìù Contenuto del system prompt:\")\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90257582",
   "metadata": {},
   "source": [
    "### Testiamo il System Prompt con Few-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "267a66cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risposta con few-shot:\n",
      "üá≤üáæ Kuala Lumpur √® la capitale della Malesia. Popolazione: ~1.9‚ÄØM abitanti. Famosa per: Petronas Twin Towers, Batu Caves, gastronomia di strada (nasi lemak, satay), Chinatown, i giardini del Lago (Lake Gardens).\n"
     ]
    }
   ],
   "source": [
    "# Testiamo il system prompt con un agente\n",
    "# Testiamo con una nuova citt√†\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=system_prompt\n",
    ")\n",
    "\n",
    "response = agent.invoke({\"messages\": \"Kuala Lumpur\"})\n",
    "print(\"Risposta con few-shot:\")\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c0de71",
   "metadata": {},
   "source": [
    "### üé® Tecnica 2: Controllare il Formato dell'Output tramite Prompt\n",
    "\n",
    "Invece di usare output strutturati con Pydantic, possiamo guidare il formato attraverso il prompt stesso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5e92c9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Output JSON:\n",
      "{\n",
      "    \"risposta\": \"Lisboa\",\n",
      "    \"fonti\": [\"https://it.wikipedia.org/wiki/Portogallo\", \"https://www.britannica.com/place/Portugal\"],\n",
      "    \"confidenza\": \"alta\"\n",
      "}\n",
      "\n",
      "‚úÖ JSON valido! Risposta: Lisboa\n",
      "Confidenza: alta\n"
     ]
    }
   ],
   "source": [
    "# Esempio 1: Output in formato JSON\n",
    "json_system_prompt = \"\"\"Sei un assistente che risponde SEMPRE in formato JSON valido.\n",
    "    \n",
    "Struttura richiesta:\n",
    "{\n",
    "    \"risposta\": \"la tua risposta qui\",\n",
    "    \"fonti\": [\"fonte1\", \"fonte2\"],\n",
    "    \"confidenza\": \"alta/media/bassa\"\n",
    "}\n",
    "\n",
    "Non aggiungere testo al di fuori del JSON.\"\"\"\n",
    "\n",
    "# Creiamo un agente con il system prompt JSON\n",
    "json_agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=json_system_prompt\n",
    ")\n",
    "\n",
    "response = json_agent.invoke({\"messages\": \"Qual √® la capitale del Portogallo?\"})\n",
    "print(\"üìÑ Output JSON:\")\n",
    "print(response['messages'][-1].content)\n",
    "\n",
    "# Possiamo parsare il JSON\n",
    "import json\n",
    "try:\n",
    "    data = json.loads(response['messages'][-1].content)\n",
    "    print(f\"\\n‚úÖ JSON valido! Risposta: {data['risposta']}\")\n",
    "    print(f\"Confidenza: {data['confidenza']}\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Formato non valido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dbdb40c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Output Markdown:\n",
      "# Cos‚Äô√® una API REST\n",
      "\n",
      "## Definizione generale\n",
      "Una **API REST** (Representational State Transfer) √® un insieme di regole e convenzioni per la creazione di **servizi web** che comunicano tramite il protocollo **HTTP**.  \n",
      "REST non √® uno standard rigido, ma un **architettura** che si basa su principi ben definiti per garantire interoperabilit√†, scalabilit√† e semplicit√†.\n",
      "\n",
      "## Principi chiave di REST\n",
      "\n",
      "- **Stateless (senza stato)**  \n",
      "  Ogni richiesta del client deve contenere tutte le informazioni necessarie per essere compresa dal server. Il server non conserva alcuna informazione sullo stato della sessione.\n",
      "\n",
      "- **Client‚ÄëServer**  \n",
      "  Separazione netta tra client (che richiede risorse) e server (che le fornisce). Questo favorisce lo sviluppo indipendente di entrambi i lati.\n",
      "\n",
      "- **Cacheable (memorizzabile)**  \n",
      "  Le risposte HTTP possono essere marcate come cacheable o non‚Äëcacheable, consentendo ai client o a intermediari di memorizzare temporaneamente le risposte per ridurre il traffico.\n",
      "\n",
      "- **Uniform Interface (interfaccia uniforme)**  \n",
      "  Le interazioni avvengono tramite un set limitato di operazioni ben definite (GET, POST, PUT, PATCH, DELETE, ecc.) e risorse identificate da URL.\n",
      "\n",
      "- **Layered System (sistema a strati)**  \n",
      "  Un client non deve sapere se sta comunicando direttamente con il server finale o con un intermediario (es. bilanciatore, gateway).\n",
      "\n",
      "- **Code on Demand (opzionale)**  \n",
      "  Il server pu√≤ inviare codice eseguibile (es. JavaScript) che il client pu√≤ eseguire per estendere le sue funzionalit√†.\n",
      "\n",
      "## Risorse e URL\n",
      "\n",
      "In REST le **risorse** (ad es. utenti, ordini, prodotti) sono identificate da **URL** univoci.  \n",
      "Esempio di URL per una risorsa ‚Äúutenti‚Äù:\n",
      "\n",
      "```\n",
      "https://api.miosito.com/v1/users\n",
      "```\n",
      "\n",
      "- **Collezioni**: `/users` ‚Äì rappresenta tutti gli utenti.\n",
      "- **Elemento specifico**: `/users/123` ‚Äì rappresenta l'utente con ID 123.\n",
      "\n",
      "## Verbi HTTP pi√π comuni\n",
      "\n",
      "| Verbo | Azione tipica | Esempio di uso |\n",
      "|-------|---------------|----------------|\n",
      "| **GET** | Recupera una risorsa (senza modificarla) | `GET /users/123` |\n",
      "| **POST** | Crea una nuova risorsa nella collezione | `POST /users` (con body JSON) |\n",
      "| **PUT** | Sostituisce interamente una risorsa esistente | `PUT /users/123` |\n",
      "| **PATCH** | Aggiorna parzialmente una risorsa | `PATCH /users/123` |\n",
      "| **DELETE** | Rimuove una risorsa | `DELETE /users/123` |\n",
      "\n",
      "## Formato dei dati\n",
      "\n",
      "- **JSON** √® il formato pi√π usato per scambiare dati (ma anche XML, YAML, ecc. sono possibili).  \n",
      "- Il server indica il tipo di contenuto con l'header `Content-Type`.\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"id\": 123,\n",
      "  \"name\": \"Mario Rossi\",\n",
      "  \"email\": \"mario@example.com\"\n",
      "}\n",
      "```\n",
      "\n",
      "## Codici di stato HTTP pi√π rilevanti\n",
      "\n",
      "- **200 OK** ‚Äì Richiesta completata con successo.\n",
      "- **201 Created** ‚Äì Risorsa creata (tipicamente in risposta a `POST`).\n",
      "- **204 No Content** ‚Äì Operazione completata, nessun contenuto da restituire (es. `DELETE`).\n",
      "- **400 Bad Request** ‚Äì Richiesta malformata.\n",
      "- **401 Unauthorized** ‚Äì Autenticazione necessaria o fallita.\n",
      "- **403 Forbidden** ‚Äì Accesso negato.\n",
      "- **404 Not Found** ‚Äì Risorsa non trovata.\n",
      "- **500 Internal Server Error** ‚Äì Errore interno del server.\n",
      "\n",
      "## Esempio pratico: chiamata `GET` con `curl`\n",
      "\n",
      "```bash\n",
      "curl -X GET \"https://api.miosito.com/v1/users/123\" \\\n",
      "     -H \"Accept: application/json\" \\\n",
      "     -H \"Authorization: Bearer <token>\"\n",
      "```\n",
      "\n",
      "Risposta (JSON):\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"id\": 123,\n",
      "  \"name\": \"Mario Rossi\",\n",
      "  \"email\": \"mario@example.com\",\n",
      "  \"created_at\": \"2023-07-15T10:23:00Z\"\n",
      "}\n",
      "```\n",
      "\n",
      "## Buone pratiche per progettare una API REST\n",
      "\n",
      "- **Usare nomi di risorse al plurale** (`/users`, `/orders`).  \n",
      "- **Mantenere le URL coerenti e leggibili**; evitare verbi nei percorsi (`/getUser` √® sbagliato).  \n",
      "- **Documentare l‚ÄôAPI** (es. con OpenAPI/Swagger).  \n",
      "- **Gestire correttamente gli errori** restituendo messaggi chiari e codici di stato appropriati.  \n",
      "- **Versionare l‚ÄôAPI** (`/v1/`, `/v2/`) per garantire retro‚Äëcompatibilit√†.  \n",
      "- **Proteggere le risorse** con autenticazione (JWT, OAuth) e autorizzazione.  \n",
      "- **Limitare la dimensione delle risposte** (paginazione, filtraggio, selezione dei campi) per migliorare le performance.\n",
      "\n",
      "---\n",
      "\n",
      "**In sintesi**, una **API REST** √® un modo standardizzato e leggero per esporre risorse tramite HTTP, basato su principi di statelessness, uniformit√† e utilizzo di verbi HTTP per operazioni CRUD. Seguendo le linee guida sopra, √® possibile costruire servizi web scalabili, manutenibili e facilmente consumabili da qualsiasi client.\n"
     ]
    }
   ],
   "source": [
    "# Esempio 2: Output in formato Markdown\n",
    "markdown_system_prompt = \"\"\"Sei un assistente tecnico che risponde SEMPRE in formato Markdown ben strutturato.\n",
    "\n",
    "Usa:\n",
    "- # per il titolo principale\n",
    "- ## per le sezioni\n",
    "- **grassetto** per enfatizzare\n",
    "- `code` per codice inline\n",
    "- ```language per blocchi di codice\n",
    "- - per liste puntate\n",
    "- 1. per liste numerate\n",
    "\n",
    "Sii sempre chiaro e ben formattato.\"\"\"\n",
    "\n",
    "# Creiamo un agente con il system prompt Markdown\n",
    "markdown_agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=markdown_system_prompt\n",
    ")\n",
    "\n",
    "response = markdown_agent.invoke({\"messages\": \"Spiega cos'√® una API REST\"})\n",
    "print(\"üìù Output Markdown:\")\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d11551fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Output CSV:\n",
      "Linguaggio,Anno,Creatore\n",
      "Python,1991,Guido van Rossum\n",
      "Java,1995,James Gosling\n",
      "C++,1985,Bjarne Stroustrup\n",
      "\n",
      "‚úÖ CSV parsato:\n",
      "  {'Linguaggio': 'Python', 'Anno': '1991', 'Creatore': 'Guido van Rossum'}\n",
      "  {'Linguaggio': 'Java', 'Anno': '1995', 'Creatore': 'James Gosling'}\n",
      "  {'Linguaggio': 'C++', 'Anno': '1985', 'Creatore': 'Bjarne Stroustrup'}\n"
     ]
    }
   ],
   "source": [
    "# Esempio 3: Output in formato CSV/Tabella\n",
    "csv_system_prompt = \"\"\"Sei un assistente che genera dati in formato CSV.\n",
    "\n",
    "Rispondi SEMPRE con:\n",
    "1. Prima riga: intestazioni separate da virgola\n",
    "2. Righe successive: dati separati da virgola\n",
    "3. Non aggiungere testo esplicativo\n",
    "\n",
    "Esempio:\n",
    "Nome,Et√†,Citt√†\n",
    "Mario,30,Roma\n",
    "Luigi,25,Milano\"\"\"\n",
    "\n",
    "# Creiamo un agente con il system prompt CSV\n",
    "csv_agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=csv_system_prompt\n",
    ")\n",
    "\n",
    "response = csv_agent.invoke({\"messages\": \"Crea una lista di 3 linguaggi di programmazione con anno di creazione e creatore\"})\n",
    "print(\"üìä Output CSV:\")\n",
    "print(response['messages'][-1].content)\n",
    "\n",
    "# Possiamo parsare il CSV\n",
    "import csv\n",
    "from io import StringIO\n",
    "\n",
    "try:\n",
    "    csv_data = StringIO(response['messages'][-1].content)\n",
    "    reader = csv.DictReader(csv_data)\n",
    "    print(\"\\n‚úÖ CSV parsato:\")\n",
    "    for row in reader:\n",
    "        print(f\"  {row}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Errore nel parsing: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5702e4d1",
   "metadata": {},
   "source": [
    "### üí° Best Practices per System Prompt\n",
    "\n",
    "**Per Few-Shot Examples:**\n",
    "- Usa 3-5 esempi di qualit√† (non troppi!)\n",
    "- Esempi devono essere rappresentativi del compito\n",
    "- Mantieni formato consistente tra gli esempi\n",
    "- Includi casi edge se necessario\n",
    "\n",
    "**Per Controllare il Formato:**\n",
    "- Sii **molto specifico** sul formato desiderato\n",
    "- Fornisci esempi del formato nel system prompt\n",
    "- Specifica cosa NON fare (es: \"non aggiungere spiegazioni\")\n",
    "- Usa delimitatori chiari (JSON, XML, CSV, ecc.)\n",
    "- Considera di validare/parsare l'output\n",
    "\n",
    "**Quando usare Prompt vs Pydantic:**\n",
    "- **Prompt**: Pi√π flessibile, ma meno affidabile\n",
    "- **Pydantic (with_structured_output)**: Pi√π robusto, garantito, ma richiede definizione schema\n",
    "\n",
    "üí° **Tip**: Combina entrambi! Usa Pydantic per dati critici e prompt per output creativi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed68d4ee",
   "metadata": {},
   "source": [
    "## 6. Creare un Tool Personalizzato\n",
    "\n",
    "I **tools** sono funzioni che l'agente pu√≤ chiamare per eseguire azioni specifiche.\n",
    "\n",
    "Creiamo un tool semplice per ottenere informazioni meteo (simulato):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "35b178f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tool 'get_weather' creato\n",
      "Nome: get_weather\n",
      "Descrizione: Ottieni le informazioni meteo per una citt√†.\n",
      "\n",
      "Args:\n",
      "    city: Il nome della citt√† per cui ottenere il meteo\n",
      "\n",
      "Returns:\n",
      "    Le condizioni meteo attuali\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Ottieni le informazioni meteo per una citt√†.\n",
    "    \n",
    "    Args:\n",
    "        city: Il nome della citt√† per cui ottenere il meteo\n",
    "        \n",
    "    Returns:\n",
    "        Le condizioni meteo attuali\n",
    "    \"\"\"\n",
    "    # Questa √® una simulazione - in un'app reale chiameresti un'API meteo\n",
    "    weather_data = {\n",
    "        \"roma\": \"‚òÄÔ∏è Soleggiato, 22¬∞C\",\n",
    "        \"milano\": \"üåßÔ∏è Piovoso, 18¬∞C\",\n",
    "        \"napoli\": \"‚õÖ Parzialmente nuvoloso, 24¬∞C\",\n",
    "    }\n",
    "    \n",
    "    city_lower = city.lower()\n",
    "    return weather_data.get(city_lower, f\"üåç Dati meteo non disponibili per {city}\")\n",
    "\n",
    "print(\"‚úÖ Tool 'get_weather' creato\")\n",
    "print(f\"Nome: {get_weather.name}\")\n",
    "print(f\"Descrizione: {get_weather.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851f3edd",
   "metadata": {},
   "source": [
    "### Test del Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1c242bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚òÄÔ∏è Soleggiato, 22¬∞C\n"
     ]
    }
   ],
   "source": [
    "# Testiamo il tool direttamente\n",
    "result = get_weather.invoke({\"city\": \"Roma\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87139683",
   "metadata": {},
   "source": [
    "### Aggiungiamo un Altro Tool: Calcolatrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2d245fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tool 'calculator' creato\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Esegui un calcolo matematico semplice.\n",
    "    \n",
    "    Args:\n",
    "        expression: Espressione matematica da calcolare (es: '2 + 2', '10 * 5')\n",
    "        \n",
    "    Returns:\n",
    "        Il risultato del calcolo\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ATTENZIONE: eval() √® usato qui solo per demo educative\n",
    "        # In produzione, usa librerie sicure come asteval o simpleeval\n",
    "        result = eval(expression)\n",
    "        return f\"Il risultato √®: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Errore nel calcolo: {str(e)}\"\n",
    "\n",
    "print(\"‚úÖ Tool 'calculator' creato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c974d638",
   "metadata": {},
   "source": [
    "## 7. Aggiungere Tools all'Agente\n",
    "\n",
    "Ora creiamo un agente pi√π potente aggiungendo i tools che abbiamo definito prima:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2c3ad02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agente con tools creato!\n"
     ]
    }
   ],
   "source": [
    "# Creiamo l'agente CON tools\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather, calculator],\n",
    "    system_prompt=\"\"\"Sei un assistente utile che pu√≤:\n",
    "    1. Fornire informazioni sul meteo\n",
    "    2. Eseguire calcoli matematici\n",
    "    \n",
    "    Usa i tools disponibili quando necessario e rispondi sempre in italiano.\"\"\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Agente con tools creato!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9ea04e",
   "metadata": {},
   "source": [
    "## 8. Usare l'Agente con Tools\n",
    "\n",
    "Testiamo l'agente con alcune domande che richiedono l'uso dei tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed08a8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agente: A Roma c'√® il sole e la temperatura √® di circa 22‚ÄØ¬∞C.\n"
     ]
    }
   ],
   "source": [
    "# Domanda sul meteo\n",
    "response = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Che tempo fa a Roma?\"}]\n",
    "})\n",
    "\n",
    "# Estraiamo la risposta finale\n",
    "final_message = response[\"messages\"][-1]\n",
    "\n",
    "print(f\"Agente: {final_message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c6d0bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agente: Il risultato di \\(123 \\times 456\\) √® **56‚ÄØ088**.\n"
     ]
    }
   ],
   "source": [
    "# Domanda matematica\n",
    "response = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Quanto fa 123 * 456?\"}]\n",
    "})\n",
    "\n",
    "final_message = response[\"messages\"][-1]\n",
    "print(f\"Agente: {final_message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52bf5fe",
   "metadata": {},
   "source": [
    "## 9. Output Strutturati\n",
    "\n",
    "Spesso vogliamo che l'agente restituisca dati in un formato strutturato (JSON, Pydantic models, ecc.) invece di testo libero.\n",
    "\n",
    "LangChain supporta gli **output strutturati** tramite `.with_structured_output()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "029ffe94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modello Pydantic definito\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# Definiamo la struttura dati desiderata\n",
    "class WeatherResponse(BaseModel):\n",
    "    \"\"\"Risposta strutturata con informazioni meteo\"\"\"\n",
    "    city: str = Field(description=\"Nome della citt√†\")\n",
    "    temperature: int = Field(description=\"Temperatura in gradi Celsius\")\n",
    "    condition: str = Field(description=\"Condizione meteo (es: soleggiato, nuvoloso, piovoso)\")\n",
    "    recommendations: List[str] = Field(description=\"Raccomandazioni per l'utente\")\n",
    "\n",
    "print(\"‚úÖ Modello Pydantic definito\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d5c67b",
   "metadata": {},
   "source": [
    "### Creare un Modello con Output Strutturato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0945025a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo di risposta: <class '__main__.WeatherResponse'>\n",
      "\n",
      "Oggetto strutturato:\n",
      "Citt√†: Milano\n",
      "Temperatura: 10¬∞C\n",
      "Condizione: pioggia leggera\n",
      "Raccomandazioni: Indossa un cappotto impermeabile e una sciarpa., Porta con te un ombrello o un impermeabile leggero., Calzature chiuse e antiscivolo per evitare scivolamenti., Se possibile, limita le attivit√† all'aperto durante le ore pi√π fredde.\n"
     ]
    }
   ],
   "source": [
    "# Creiamo un modello che restituisce output strutturati\n",
    "structured_model = model.with_structured_output(WeatherResponse)\n",
    "\n",
    "# Alternativamente, possiamo creare un agente con output strutturato nell'inizializzazione\n",
    "# structured_agent = create_agent(\n",
    "#     model=model,\n",
    "#     system_prompt=...,\n",
    "#     response_format=WeatherResponse,\n",
    "# )\n",
    "\n",
    "# Testiamo con una richiesta\n",
    "response = structured_model.invoke(\n",
    "    \"Dimmi il meteo a Milano. Fa freddo con pioggia leggera, circa 10 gradi.\"\n",
    ")\n",
    "\n",
    "print(\"Tipo di risposta:\", type(response))\n",
    "print(\"\\nOggetto strutturato:\")\n",
    "print(f\"Citt√†: {response.city}\")\n",
    "print(f\"Temperatura: {response.temperature}¬∞C\")\n",
    "print(f\"Condizione: {response.condition}\")\n",
    "print(f\"Raccomandazioni: {', '.join(response.recommendations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07e25e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Tasks generati:\n",
      "\n",
      "1. Scegliere e ordinare la torta di compleanno\n",
      "   Priorit√†: alta\n",
      "   Tempo: 2 ore\n",
      "\n",
      "2. Invitare gli ospiti e confermare la presenza\n",
      "   Priorit√†: media\n",
      "   Tempo: 1 ora\n",
      "\n",
      "3. Allestire la location (decorazioni, tavoli, musica)\n",
      "   Priorit√†: media\n",
      "   Tempo: 3 ore\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Task(BaseModel):\n",
    "    \"\"\"Un task da completare\"\"\"\n",
    "    title: str = Field(description=\"Titolo del task\")\n",
    "    priority: str = Field(description=\"Priorit√†: alta, media, bassa\")\n",
    "    estimated_time: str = Field(description=\"Tempo stimato per completarlo\")\n",
    "\n",
    "class TaskList(BaseModel):\n",
    "    \"\"\"Lista di tasks\"\"\"\n",
    "    tasks: List[Task] = Field(description=\"Lista di tasks da completare\")\n",
    "\n",
    "# Modello che restituisce lista di tasks\n",
    "task_model = model.with_structured_output(TaskList)\n",
    "\n",
    "# Richiesta\n",
    "response = task_model.invoke(\n",
    "    \"Crea una lista di 3 tasks per organizzare una festa di compleanno\"\n",
    ")\n",
    "\n",
    "print(\"üìã Tasks generati:\\n\")\n",
    "for i, task in enumerate(response.tasks, 1):\n",
    "    print(f\"{i}. {task.title}\")\n",
    "    print(f\"   Priorit√†: {task.priority}\")\n",
    "    print(f\"   Tempo: {task.estimated_time}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f67c93",
   "metadata": {},
   "source": [
    "## 10. Aggiungere Memoria a Breve Termine (Checkpointer)\n",
    "\n",
    "**Problema:** L'agente attuale non ricorda le conversazioni precedenti.\n",
    "\n",
    "**Soluzione:** Aggiungiamo un **checkpointer** per salvare lo stato della conversazione.\n",
    "\n",
    "I checkpointer permettono:\n",
    "- üíæ Persistenza della conversazione\n",
    "- üîÑ Continuit√† tra le interazioni\n",
    "- üéØ Memoria contestuale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c95ac9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agente con memoria creato!\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Creiamo un checkpointer in-memory\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# Creiamo un nuovo agente CON memoria\n",
    "agent_with_memory = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather, calculator],\n",
    "    system_prompt=\"\"\"Sei un assistente utile che pu√≤:\n",
    "    1. Fornire informazioni sul meteo\n",
    "    2. Eseguire calcoli matematici\n",
    "    \n",
    "    Usa i tools disponibili quando necessario e rispondi sempre in italiano.\n",
    "    Ricorda le informazioni delle conversazioni precedenti.\"\"\",\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Agente con memoria creato!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47067010",
   "metadata": {},
   "source": [
    "### üß™ Testiamo la Memoria\n",
    "\n",
    "Per usare la memoria, dobbiamo specificare un `thread_id` che identifica la conversazione:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51078e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agente: Ciao Marco! Piacere di conoscerti. üòä Come posso aiutarti oggi? Posso darti informazioni sul meteo, fare qualche calcolo o rispondere ad altre tue domande.\n"
     ]
    }
   ],
   "source": [
    "# Configurazione con thread_id per identificare la conversazione\n",
    "config = {\"configurable\": {\"thread_id\": \"conversazione-1\"}}\n",
    "\n",
    "# Primo messaggio: ci presentiamo\n",
    "response = agent_with_memory.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Ciao! Mi chiamo Marco.\"}]},\n",
    "    config\n",
    ")\n",
    "\n",
    "print(\"Agente:\", response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2496b7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agente: A Roma c'√® il sole, con una temperatura attorno ai 22‚ÄØ¬∞C. ‚òÄÔ∏è Hai bisogno di ulteriori dettagli o di altre informazioni?\n"
     ]
    }
   ],
   "source": [
    "# Secondo messaggio: chiediamo il meteo\n",
    "response = agent_with_memory.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Che tempo fa a Roma?\"}]},\n",
    "    config\n",
    ")\n",
    "\n",
    "print(\"Agente:\", response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65e9be9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agente: Ti chiami Marco. üòä\n",
      "\n",
      "‚úÖ L'agente ricorda il nome! La memoria funziona!\n"
     ]
    }
   ],
   "source": [
    "# Terzo messaggio: verifichiamo se ricorda il nostro nome!\n",
    "response = agent_with_memory.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Come mi chiamo?\"}]},\n",
    "    config\n",
    ")\n",
    "\n",
    "print(\"Agente:\", response[\"messages\"][-1].content)\n",
    "print(\"\\n‚úÖ L'agente ricorda il nome! La memoria funziona!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e030ca1",
   "metadata": {},
   "source": [
    "### üÜï Thread Diversi = Conversazioni Separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3325965f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agente (nuova conversazione): Non lo so, mi potresti ricordare il tuo nome?\n",
      "\n",
      "üí° In un nuovo thread, l'agente non ha memoria della conversazione precedente!\n"
     ]
    }
   ],
   "source": [
    "# Creiamo una NUOVA conversazione con un thread_id diverso\n",
    "config_2 = {\"configurable\": {\"thread_id\": \"conversazione-2\"}}\n",
    "\n",
    "response = agent_with_memory.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Come mi chiamo?\"}]},\n",
    "    config_2\n",
    ")\n",
    "\n",
    "print(\"Agente (nuova conversazione):\", response[\"messages\"][-1].content)\n",
    "print(\"\\nüí° In un nuovo thread, l'agente non ha memoria della conversazione precedente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c28020",
   "metadata": {},
   "source": [
    "### üîç Visualizziamo la Storia della Conversazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3f4f3138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Ciao! Mi chiamo Marco.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ciao Marco! Piacere di conoscerti. üòä Come posso aiutarti oggi? Posso darti informazioni sul meteo, fare qualche calcolo o rispondere ad altre tue domande.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Che tempo fa a Roma?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (3c8998934)\n",
      " Call ID: 3c8998934\n",
      "  Args:\n",
      "    city: Roma\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "‚òÄÔ∏è Soleggiato, 22¬∞C\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "A Roma c'√® il sole, con una temperatura attorno ai 22‚ÄØ¬∞C. ‚òÄÔ∏è Hai bisogno di ulteriori dettagli o di altre informazioni?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Come mi chiamo?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ti chiami Marco. üòä\n"
     ]
    }
   ],
   "source": [
    "# Otteniamo lo stato corrente del thread\n",
    "state = agent_with_memory.get_state(config)\n",
    "\n",
    "for r in state.values['messages']:\n",
    "    r.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab42cc60",
   "metadata": {},
   "source": [
    "## 11. Checkpointer in Produzione\n",
    "\n",
    "Per applicazioni reali, usa checkpointer persistenti:\n",
    "\n",
    "```python\n",
    "# PostgreSQL\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "checkpointer = PostgresSaver.from_conn_string(\n",
    "    \"postgresql://user:pass@localhost:5432/db\"\n",
    ")\n",
    "\n",
    "# Redis\n",
    "from langgraph.checkpoint.redis import RedisSaver\n",
    "checkpointer = RedisSaver.from_conn_info(\n",
    "    host=\"localhost\", port=6379\n",
    ")\n",
    "\n",
    "# MongoDB\n",
    "from langgraph.checkpoint.mongodb import MongoDBSaver\n",
    "checkpointer = MongoDBSaver.from_conn_string(\n",
    "    \"mongodb://localhost:27017\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dba1dec",
   "metadata": {},
   "source": [
    "## üéØ Esercizio Pratico\n",
    "\n",
    "Crea un agente che:\n",
    "\n",
    "1. Ha almeno UN tool personalizzato (scegli tu quale!)\n",
    "2. Ha un system prompt appropriato (magari con few-shot examples!)\n",
    "3. Usa la memoria per ricordare le interazioni\n",
    "4. *BONUS*: Restituisce output strutturati con Pydantic o formato controllato tramite prompt\n",
    "\n",
    "Idee per tools:\n",
    "- `search_wiki(query)` - cerca su Wikipedia (simulato)\n",
    "- `translate(text, target_lang)` - traduce testo\n",
    "- `get_recipe(dish)` - ottiene una ricetta\n",
    "- `convert_currency(amount, from_curr, to_curr)` - converte valuta\n",
    "- `generate_password(length)` - genera password sicura\n",
    "\n",
    "```python\n",
    "# Il tuo codice qui\n",
    "\n",
    "@tool\n",
    "def my_custom_tool(...):\n",
    "    \\\"\\\"\\\"...\\\"\\\"\\\"\n",
    "    pass\n",
    "\n",
    "# Crea l'agente\n",
    "my_agent = create_agent(...)\n",
    "\n",
    "# Testalo!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d23af57",
   "metadata": {},
   "source": [
    "## üìö Riepilogo\n",
    "\n",
    "In questa lezione hai imparato:\n",
    "\n",
    "- ‚úÖ **`init_chat_model`**: Inizializzare modelli con interfaccia unificata\n",
    "- ‚úÖ **Tools**: Creare funzioni che l'agente pu√≤ chiamare\n",
    "- ‚úÖ **System Prompts Avanzati**: Few-shot examples e controllo formato output\n",
    "- ‚úÖ **`create_agent`**: Creare agenti semplici e con tools\n",
    "- ‚úÖ **Output Strutturati**: Ottenere dati in formato JSON/Pydantic\n",
    "- ‚úÖ **Checkpointer**: Aggiungere memoria a breve termine\n",
    "- ‚úÖ **Thread ID**: Gestire conversazioni separate\n",
    "\n",
    "### üîë Concetti Chiave\n",
    "\n",
    "1. **Gli agenti LangChain sono costruiti su LangGraph** - ottieni robustezza e flessibilit√†\n",
    "2. **Inizia semplice, poi aggiungi tools** - costruisci incrementalmente\n",
    "3. **Few-shot examples guidano il comportamento** - usa 3-5 esempi di qualit√†\n",
    "4. **Prompt vs Pydantic per output** - scegli in base a flessibilit√† vs garanzie\n",
    "5. **La memoria √® essenziale per conversazioni naturali** - usa sempre checkpointer in produzione\n",
    "6. **Thread ID separate = conversazioni separate** - utile per applicazioni multi-utente\n",
    "\n",
    "### üöÄ Prossimi Passi\n",
    "\n",
    "Nella prossima lezione esploreremo:\n",
    "- Agenti multi-tool pi√π complessi\n",
    "- Gestione avanzata degli errori\n",
    "- Streaming delle risposte\n",
    "- Human-in-the-loop patterns\n",
    "- RAG (Retrieval Augmented Generation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-corso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
