{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00fbeaba",
   "metadata": {},
   "source": [
    "# Lezione 1: Introduzione agli Agenti LangChain\n",
    "\n",
    "Benvenuti alla prima lezione del corso! In questo notebook imparerete:\n",
    "\n",
    "1. Come inizializzare un modello con `init_chat_model`\n",
    "2. Come creare un agente con `create_agent`\n",
    "3. Come configurare prompts e system prompts\n",
    "4. Come aggiungere tools agli agenti\n",
    "5. Come aggiungere memoria a breve termine (checkpointer)\n",
    "6. Come configurare un agente con Tavily per cercare informazioni online"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6b513c",
   "metadata": {},
   "source": [
    "## 1. Verifica Setup\n",
    "\n",
    "Prima di tutto, verifichiamo che tutto sia configurato correttamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e4b54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiamo le librerie necessarie\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "try:\n",
    "    import langchain\n",
    "    import langgraph\n",
    "    from importlib.metadata import version\n",
    "    print(f\"‚úÖ LangChain version: {langchain.__version__}\")\n",
    "    print(f\"‚úÖ LangGraph version: {version('langgraph')}\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Errore import: {e}\")\n",
    "    print(\"Esegui: uv sync\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a7c4f5",
   "metadata": {},
   "source": [
    "## 2. Caricamento API Keys\n",
    "\n",
    "Carichiamo le API keys dal file `.env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d2cb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carica le variabili d'ambiente dal file .env\n",
    "load_dotenv()\n",
    "\n",
    "# Verifica che la chiave sia stata caricata\n",
    "if os.getenv(\"OPENAI_API_KEY\") or os.getenv(\"CEREBRAS_API_KEY\"):\n",
    "    print(\"‚úÖ API key caricata correttamente\")\n",
    "else:\n",
    "    print(\"‚ùå API key non trovata. Assicurati di aver configurato il file .env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9656d00c",
   "metadata": {},
   "source": [
    "## 3. Inizializzare un Modello con `init_chat_model`\n",
    "\n",
    "`init_chat_model` √® il modo standard per inizializzare un modello di chat in LangChain.\n",
    "\n",
    "**Vantaggi:**\n",
    "- Interfaccia unificata per qualsiasi provider (OpenAI, Anthropic, Google, ecc.)\n",
    "- Facile cambiare provider senza modificare il codice\n",
    "- Configurazione semplificata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1686dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Inizializziamo il modello - sintassi semplice!\n",
    "# Formato: \"provider:model-name\"\n",
    "\n",
    "model = init_chat_model(\n",
    "    \"openai:gpt-3.5-turbo\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Modello inizializzato\")\n",
    "print(f\"Tipo: {type(model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08621749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALTERNATIVA: Usare Cerebras (pi√π veloce ed economico)\n",
    "# Installiamo langchain-cerebras se non √® presente\n",
    "# uv add langchain-cerebras (nel terminale)\n",
    "\n",
    "# Ora possiamo usare Cerebras\n",
    "#from langchain_cerebras import ChatCerebras\n",
    "#model = ChatCerebras(model=\"gpt-oss-120b\", temperature=0.7)\n",
    "#print(\"‚úÖ Modello Cerebras inizializzato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d39a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test rapido del modello\n",
    "response = model.invoke(\"Ciao! In una frase, spiegami cos'√® un agente AI.\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf3f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a289ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ea11af",
   "metadata": {},
   "source": [
    "### Cambiare Provider √® Facile!\n",
    "\n",
    "Per usare un altro modello, basta cambiare la stringa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e074871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esempi di altri provider (commentati)\n",
    "\n",
    "# Anthropic Claude\n",
    "# model = init_chat_model(\"anthropic:claude-3-5-sonnet-20241022\", temperature=0.7)\n",
    "\n",
    "# Google Gemini  \n",
    "# model = init_chat_model(\"google_genai:gemini-2.5-flash-lite\", temperature=0.7)\n",
    "\n",
    "# Groq\n",
    "# model = init_chat_model(\"groq:llama-3.1-70b-versatile\", temperature=0.7)\n",
    "\n",
    "print(\"Puoi cambiare provider semplicemente modificando la stringa del modello!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea732c3",
   "metadata": {},
   "source": [
    "## 4. Creare un Agente Semplice con `create_agent`\n",
    "\n",
    "`create_agent` √® la nuova API semplificata per creare agenti in LangChain.\n",
    "\n",
    "**Caratteristiche:**\n",
    "- Costruito sopra LangGraph per robustezza\n",
    "- API semplice per casi d'uso comuni\n",
    "- Supporta tools, system prompts e memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50ba952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# Creiamo un agente semplice\n",
    "simple_agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=\"Sei un assistente utile che risponde sempre in italiano in modo conciso.\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Agente semplice creato!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ec5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testiamo l'agente semplice\n",
    "response = simple_agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Ciao! Chi sei?\"}]\n",
    "})\n",
    "\n",
    "print(\"Agente:\", response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7186db",
   "metadata": {},
   "source": [
    "## 5. System Prompt e Tecniche di Prompting\n",
    "\n",
    "I **system prompt** sono fondamentali per guidare il comportamento dell'LLM. Vediamo tecniche avanzate per ottenere risultati migliori."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64a2c3e",
   "metadata": {},
   "source": [
    "### üìù Tecnica 1: Few-Shot Examples\n",
    "\n",
    "Il **few-shot prompting** consiste nel fornire esempi al modello per guidarlo verso il formato/stile desiderato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5971df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo un system prompt con few-shot examples\n",
    "# Questo pu√≤ essere usato direttamente con create_agent()\n",
    "\n",
    "system_prompt = \"\"\"Sei un esperto di geografia. Rispondi seguendo il formato degli esempi forniti.\n",
    "\n",
    "Esempi:\n",
    "\n",
    "Utente: Parigi\n",
    "Assistente: üá´üá∑ Parigi √® la capitale della Francia. Popolazione: ~2.2M abitanti. Famosa per: Torre Eiffel, Louvre, Notre-Dame.\n",
    "\n",
    "Utente: Tokyo\n",
    "Assistente: üáØüáµ Tokyo √® la capitale del Giappone. Popolazione: ~14M abitanti. Famosa per: Monte Fuji, Shibuya, templi antichi.\n",
    "\n",
    "Utente: Roma\n",
    "Assistente: üáÆüáπ Roma √® la capitale dell'Italia. Popolazione: ~2.8M abitanti. Famosa per: Colosseo, Vaticano, Fontana di Trevi.\n",
    "\n",
    "Ora rispondi tu seguendo lo stesso stile e formato!\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚úÖ System prompt con few-shot examples creato\")\n",
    "print(\"\\nüìù Contenuto del system prompt:\")\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90257582",
   "metadata": {},
   "source": [
    "### Testiamo il System Prompt con Few-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267a66cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testiamo il system prompt con un agente\n",
    "# Testiamo con una nuova citt√†\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=system_prompt\n",
    ")\n",
    "\n",
    "response = agent.invoke({\"messages\": \"Kuala Lumpur\"})\n",
    "print(\"Risposta con few-shot:\")\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c0de71",
   "metadata": {},
   "source": [
    "### üé® Tecnica 2: Controllare il Formato dell'Output tramite Prompt\n",
    "\n",
    "Invece di usare output strutturati con Pydantic, possiamo guidare il formato attraverso il prompt stesso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e92c9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esempio 1: Output in formato JSON\n",
    "json_system_prompt = \"\"\"Sei un assistente che risponde SEMPRE in formato JSON valido.\n",
    "    \n",
    "Struttura richiesta:\n",
    "{\n",
    "    \"risposta\": \"la tua risposta qui\",\n",
    "    \"fonti\": [\"fonte1\", \"fonte2\"],\n",
    "    \"confidenza\": \"alta/media/bassa\"\n",
    "}\n",
    "\n",
    "Non aggiungere testo al di fuori del JSON.\"\"\"\n",
    "\n",
    "# Creiamo un agente con il system prompt JSON\n",
    "json_agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=json_system_prompt\n",
    ")\n",
    "\n",
    "response = json_agent.invoke({\"messages\": \"Qual √® la capitale del Portogallo?\"})\n",
    "print(\"üìÑ Output JSON:\")\n",
    "print(response['messages'][-1].content)\n",
    "\n",
    "# Possiamo parsare il JSON\n",
    "import json\n",
    "try:\n",
    "    data = json.loads(response['messages'][-1].content)\n",
    "    print(f\"\\n‚úÖ JSON valido! Risposta: {data['risposta']}\")\n",
    "    print(f\"Confidenza: {data['confidenza']}\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è Formato non valido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdb40c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esempio 2: Output in formato Markdown\n",
    "markdown_system_prompt = \"\"\"Sei un assistente tecnico che risponde SEMPRE in formato Markdown ben strutturato.\n",
    "\n",
    "Usa:\n",
    "- # per il titolo principale\n",
    "- ## per le sezioni\n",
    "- **grassetto** per enfatizzare\n",
    "- `code` per codice inline\n",
    "- ```language per blocchi di codice\n",
    "- - per liste puntate\n",
    "- 1. per liste numerate\n",
    "\n",
    "Sii sempre chiaro e ben formattato.\"\"\"\n",
    "\n",
    "# Creiamo un agente con il system prompt Markdown\n",
    "markdown_agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=markdown_system_prompt\n",
    ")\n",
    "\n",
    "response = markdown_agent.invoke({\"messages\": \"Spiega cos'√® una API REST\"})\n",
    "print(\"üìù Output Markdown:\")\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11551fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esempio 3: Output in formato CSV/Tabella\n",
    "csv_system_prompt = \"\"\"Sei un assistente che genera dati in formato CSV.\n",
    "\n",
    "Rispondi SEMPRE con:\n",
    "1. Prima riga: intestazioni separate da virgola\n",
    "2. Righe successive: dati separati da virgola\n",
    "3. Non aggiungere testo esplicativo\n",
    "\n",
    "Esempio:\n",
    "Nome,Et√†,Citt√†\n",
    "Mario,30,Roma\n",
    "Luigi,25,Milano\"\"\"\n",
    "\n",
    "# Creiamo un agente con il system prompt CSV\n",
    "csv_agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=csv_system_prompt\n",
    ")\n",
    "\n",
    "response = csv_agent.invoke({\"messages\": \"Crea una lista di 3 linguaggi di programmazione con anno di creazione e creatore\"})\n",
    "print(\"üìä Output CSV:\")\n",
    "print(response['messages'][-1].content)\n",
    "\n",
    "# Possiamo parsare il CSV\n",
    "import csv\n",
    "from io import StringIO\n",
    "\n",
    "try:\n",
    "    csv_data = StringIO(response['messages'][-1].content)\n",
    "    reader = csv.DictReader(csv_data)\n",
    "    print(\"\\n‚úÖ CSV parsato:\")\n",
    "    for row in reader:\n",
    "        print(f\"  {row}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Errore nel parsing: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5702e4d1",
   "metadata": {},
   "source": [
    "### üí° Best Practices per System Prompt\n",
    "\n",
    "**Per Few-Shot Examples:**\n",
    "- Usa 3-5 esempi di qualit√† (non troppi!)\n",
    "- Esempi devono essere rappresentativi del compito\n",
    "- Mantieni formato consistente tra gli esempi\n",
    "- Includi casi edge se necessario\n",
    "\n",
    "**Per Controllare il Formato:**\n",
    "- Sii **molto specifico** sul formato desiderato\n",
    "- Fornisci esempi del formato nel system prompt\n",
    "- Specifica cosa NON fare (es: \"non aggiungere spiegazioni\")\n",
    "- Usa delimitatori chiari (JSON, XML, CSV, ecc.)\n",
    "- Considera di validare/parsare l'output\n",
    "\n",
    "**Quando usare Prompt vs Pydantic:**\n",
    "- **Prompt**: Pi√π flessibile, ma meno affidabile\n",
    "- **Pydantic (with_structured_output)**: Pi√π robusto, garantito, ma richiede definizione schema\n",
    "\n",
    "üí° **Tip**: Combina entrambi! Usa Pydantic per dati critici e prompt per output creativi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed68d4ee",
   "metadata": {},
   "source": [
    "## 6. Creare un Tool Personalizzato\n",
    "\n",
    "I **tools** sono funzioni che l'agente pu√≤ chiamare per eseguire azioni specifiche.\n",
    "\n",
    "Creiamo un tool semplice per ottenere informazioni meteo (simulato):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b178f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Ottieni le informazioni meteo per una citt√†.\n",
    "    \n",
    "    Args:\n",
    "        city: Il nome della citt√† per cui ottenere il meteo\n",
    "        \n",
    "    Returns:\n",
    "        Le condizioni meteo attuali\n",
    "    \"\"\"\n",
    "    # Questa √® una simulazione - in un'app reale chiameresti un'API meteo\n",
    "    weather_data = {\n",
    "        \"roma\": \"‚òÄÔ∏è Soleggiato, 22¬∞C\",\n",
    "        \"milano\": \"üåßÔ∏è Piovoso, 18¬∞C\",\n",
    "        \"napoli\": \"‚õÖ Parzialmente nuvoloso, 24¬∞C\",\n",
    "    }\n",
    "    \n",
    "    city_lower = city.lower()\n",
    "    return weather_data.get(city_lower, f\"üåç Dati meteo non disponibili per {city}\")\n",
    "\n",
    "print(\"‚úÖ Tool 'get_weather' creato\")\n",
    "print(f\"Nome: {get_weather.name}\")\n",
    "print(f\"Descrizione: {get_weather.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851f3edd",
   "metadata": {},
   "source": [
    "### Test del Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c242bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testiamo il tool direttamente\n",
    "result = get_weather.invoke({\"city\": \"Roma\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87139683",
   "metadata": {},
   "source": [
    "### Aggiungiamo un Altro Tool: Calcolatrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d245fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Esegui un calcolo matematico semplice.\n",
    "    \n",
    "    Args:\n",
    "        expression: Espressione matematica da calcolare (es: '2 + 2', '10 * 5')\n",
    "        \n",
    "    Returns:\n",
    "        Il risultato del calcolo\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ATTENZIONE: eval() √® usato qui solo per demo educative\n",
    "        # In produzione, usa librerie sicure come asteval o simpleeval\n",
    "        result = eval(expression)\n",
    "        return f\"Il risultato √®: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Errore nel calcolo: {str(e)}\"\n",
    "\n",
    "print(\"‚úÖ Tool 'calculator' creato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c974d638",
   "metadata": {},
   "source": [
    "## 7. Aggiungere Tools all'Agente\n",
    "\n",
    "Ora creiamo un agente pi√π potente aggiungendo i tools che abbiamo definito prima:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3ad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo l'agente CON tools\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather, calculator],\n",
    "    system_prompt=\"\"\"Sei un assistente utile che pu√≤:\n",
    "    1. Fornire informazioni sul meteo\n",
    "    2. Eseguire calcoli matematici\n",
    "    \n",
    "    Usa i tools disponibili quando necessario e rispondi sempre in italiano.\"\"\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Agente con tools creato!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9ea04e",
   "metadata": {},
   "source": [
    "## 8. Usare l'Agente con Tools\n",
    "\n",
    "Testiamo l'agente con alcune domande che richiedono l'uso dei tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed08a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domanda sul meteo\n",
    "response = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Che tempo fa a Roma?\"}]\n",
    "})\n",
    "\n",
    "# Estraiamo la risposta finale\n",
    "final_message = response[\"messages\"][-1]\n",
    "\n",
    "print(f\"Agente: {final_message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6d0bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domanda matematica\n",
    "response = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Quanto fa 123 * 456?\"}]\n",
    "})\n",
    "\n",
    "final_message = response[\"messages\"][-1]\n",
    "print(f\"Agente: {final_message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52bf5fe",
   "metadata": {},
   "source": [
    "## 9. Output Strutturati\n",
    "\n",
    "Spesso vogliamo che l'agente restituisca dati in un formato strutturato (JSON, Pydantic models, ecc.) invece di testo libero.\n",
    "\n",
    "LangChain supporta gli **output strutturati** tramite `.with_structured_output()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029ffe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# Definiamo la struttura dati desiderata\n",
    "class WeatherResponse(BaseModel):\n",
    "    \"\"\"Risposta strutturata con informazioni meteo\"\"\"\n",
    "    city: str = Field(description=\"Nome della citt√†\")\n",
    "    temperature: int = Field(description=\"Temperatura in gradi Celsius\")\n",
    "    condition: str = Field(description=\"Condizione meteo (es: soleggiato, nuvoloso, piovoso)\")\n",
    "    recommendations: List[str] = Field(description=\"Raccomandazioni per l'utente\")\n",
    "\n",
    "print(\"‚úÖ Modello Pydantic definito\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d5c67b",
   "metadata": {},
   "source": [
    "### Creare un Modello con Output Strutturato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0945025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo un modello che restituisce output strutturati\n",
    "structured_model = model.with_structured_output(WeatherResponse)\n",
    "\n",
    "# Alternativamente, possiamo creare un agente con output strutturato nell'inizializzazione\n",
    "# structured_agent = create_agent(\n",
    "#     model=model,\n",
    "#     system_prompt=...,\n",
    "#     response_format=WeatherResponse,\n",
    "# )\n",
    "\n",
    "# Testiamo con una richiesta\n",
    "response = structured_model.invoke(\n",
    "    \"Dimmi il meteo a Milano. Fa freddo con pioggia leggera, circa 10 gradi.\"\n",
    ")\n",
    "\n",
    "print(\"Tipo di risposta:\", type(response))\n",
    "print(\"\\nOggetto strutturato:\")\n",
    "print(f\"Citt√†: {response.city}\")\n",
    "print(f\"Temperatura: {response.temperature}¬∞C\")\n",
    "print(f\"Condizione: {response.condition}\")\n",
    "print(f\"Raccomandazioni: {', '.join(response.recommendations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e25e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task(BaseModel):\n",
    "    \"\"\"Un task da completare\"\"\"\n",
    "    title: str = Field(description=\"Titolo del task\")\n",
    "    priority: str = Field(description=\"Priorit√†: alta, media, bassa\")\n",
    "    estimated_time: str = Field(description=\"Tempo stimato per completarlo\")\n",
    "\n",
    "class TaskList(BaseModel):\n",
    "    \"\"\"Lista di tasks\"\"\"\n",
    "    tasks: List[Task] = Field(description=\"Lista di tasks da completare\")\n",
    "\n",
    "# Modello che restituisce lista di tasks\n",
    "task_model = model.with_structured_output(TaskList)\n",
    "\n",
    "# Richiesta\n",
    "response = task_model.invoke(\n",
    "    \"Crea una lista di 3 tasks per organizzare una festa di compleanno\"\n",
    ")\n",
    "\n",
    "print(\"üìã Tasks generati:\\n\")\n",
    "for i, task in enumerate(response.tasks, 1):\n",
    "    print(f\"{i}. {task.title}\")\n",
    "    print(f\"   Priorit√†: {task.priority}\")\n",
    "    print(f\"   Tempo: {task.estimated_time}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f67c93",
   "metadata": {},
   "source": [
    "## 10. Aggiungere Memoria a Breve Termine (Checkpointer)\n",
    "\n",
    "**Problema:** L'agente attuale non ricorda le conversazioni precedenti.\n",
    "\n",
    "**Soluzione:** Aggiungiamo un **checkpointer** per salvare lo stato della conversazione.\n",
    "\n",
    "I checkpointer permettono:\n",
    "- üíæ Persistenza della conversazione\n",
    "- üîÑ Continuit√† tra le interazioni\n",
    "- üéØ Memoria contestuale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ac9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Creiamo un checkpointer in-memory\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# Creiamo un nuovo agente CON memoria\n",
    "agent_with_memory = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather, calculator],\n",
    "    system_prompt=\"\"\"Sei un assistente utile che pu√≤:\n",
    "    1. Fornire informazioni sul meteo\n",
    "    2. Eseguire calcoli matematici\n",
    "    \n",
    "    Usa i tools disponibili quando necessario e rispondi sempre in italiano.\n",
    "    Ricorda le informazioni delle conversazioni precedenti.\"\"\",\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Agente con memoria creato!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47067010",
   "metadata": {},
   "source": [
    "### üß™ Testiamo la Memoria\n",
    "\n",
    "Per usare la memoria, dobbiamo specificare un `thread_id` che identifica la conversazione:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51078e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurazione con thread_id per identificare la conversazione\n",
    "config = {\"configurable\": {\"thread_id\": \"conversazione-1\"}}\n",
    "\n",
    "# Primo messaggio: ci presentiamo\n",
    "response = agent_with_memory.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Ciao! Mi chiamo Marco.\"}]},\n",
    "    config\n",
    ")\n",
    "\n",
    "print(\"Agente:\", response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2496b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secondo messaggio: chiediamo il meteo\n",
    "response = agent_with_memory.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Che tempo fa a Roma?\"}]},\n",
    "    config\n",
    ")\n",
    "\n",
    "print(\"Agente:\", response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e9be9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terzo messaggio: verifichiamo se ricorda il nostro nome!\n",
    "response = agent_with_memory.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Come mi chiamo?\"}]},\n",
    "    config\n",
    ")\n",
    "\n",
    "print(\"Agente:\", response[\"messages\"][-1].content)\n",
    "print(\"\\n‚úÖ L'agente ricorda il nome! La memoria funziona!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e030ca1",
   "metadata": {},
   "source": [
    "### üÜï Thread Diversi = Conversazioni Separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3325965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo una NUOVA conversazione con un thread_id diverso\n",
    "config_2 = {\"configurable\": {\"thread_id\": \"conversazione-2\"}}\n",
    "\n",
    "response = agent_with_memory.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Come mi chiamo?\"}]},\n",
    "    config_2\n",
    ")\n",
    "\n",
    "print(\"Agente (nuova conversazione):\", response[\"messages\"][-1].content)\n",
    "print(\"\\nüí° In un nuovo thread, l'agente non ha memoria della conversazione precedente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c28020",
   "metadata": {},
   "source": [
    "### üîç Visualizziamo la Storia della Conversazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4f3138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otteniamo lo stato corrente del thread\n",
    "state = agent_with_memory.get_state(config)\n",
    "\n",
    "for r in state.values['messages']:\n",
    "    r.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe399b2",
   "metadata": {},
   "source": [
    "## 11. üåê Agente con Ricerca Web (Tavily)\n",
    "\n",
    "**Tavily** √® un motore di ricerca ottimizzato per LLM che fornisce risultati strutturati e pertinenti.\n",
    "\n",
    "**Vantaggi:**\n",
    "- Risultati ottimizzati per AI (non HTML grezzo)\n",
    "- Pi√π veloce di Google Search\n",
    "- Filtra automaticamente contenuti irrilevanti\n",
    "- Piano gratuito disponibile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e58b4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv(\"TAVILY_API_KEY\"):\n",
    "    print(\"‚úÖ Tavily API key trovata\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Tavily API key non trovata - necessaria per ricerca web\")\n",
    "    print(\"   Ottieni una chiave su https://tavily.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97d5ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installazione Tavily (se necessario)\n",
    "# uv pip install langchain-community tavily-python\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Creiamo il tool di ricerca\n",
    "search = TavilySearchResults(\n",
    "    max_results=3,  # Numero massimo di risultati\n",
    "    search_depth=\"advanced\",  # \"basic\" o \"advanced\"\n",
    "    include_answer=True,  # Include una risposta sintetica\n",
    "    include_raw_content=False,  # Non includere HTML grezzo\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Tool Tavily Search creato\")\n",
    "print(f\"Nome tool: {search.name}\")\n",
    "print(f\"Descrizione: {search.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924053e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test diretto del tool\n",
    "result = search.invoke({\"query\": \"Ultime notizie sull'intelligenza artificiale 2026\"})\n",
    "\n",
    "print(\"üì∞ Risultati della ricerca:\\n\")\n",
    "for i, res in enumerate(result, 1):\n",
    "    print(f\"{i}. {res.get('title', 'N/A')}\")\n",
    "    print(f\"   URL: {res.get('url', 'N/A')}\")\n",
    "    print(f\"   Snippet: {res.get('content', 'N/A')[:150]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cab382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creiamo un agente con ricerca web usando la nuova API\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "search_agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[search],\n",
    "    system_prompt=\"\"\"Sei un assistente di ricerca intelligente.\n",
    "    \n",
    "Quando l'utente fa una domanda:\n",
    "1. Usa il tool di ricerca per trovare informazioni aggiornate\n",
    "2. Analizza i risultati e sintetizzali\n",
    "3. Fornisci una risposta completa citando le fonti\n",
    "4. Se le informazioni non sono sufficienti, dillo chiaramente\n",
    "\n",
    "Rispondi sempre in italiano.\"\"\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Agente di ricerca web creato con la nuova API!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d2ad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testiamo l'agente di ricerca\n",
    "response = search_agent.invoke({\n",
    "    \"messages\": \"Quali sono le novit√† pi√π importanti di LangChain nel 2026?\"\n",
    "})\n",
    "\n",
    "print(\"ü§ñ Risposta dell'agente:\\n\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab42cc60",
   "metadata": {},
   "source": [
    "## 12. Checkpointer in Produzione\n",
    "\n",
    "Per applicazioni reali, usa checkpointer persistenti:\n",
    "\n",
    "```python\n",
    "# PostgreSQL\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "checkpointer = PostgresSaver.from_conn_string(\n",
    "    \"postgresql://user:pass@localhost:5432/db\"\n",
    ")\n",
    "\n",
    "# Redis\n",
    "from langgraph.checkpoint.redis import RedisSaver\n",
    "checkpointer = RedisSaver.from_conn_info(\n",
    "    host=\"localhost\", port=6379\n",
    ")\n",
    "\n",
    "# MongoDB\n",
    "from langgraph.checkpoint.mongodb import MongoDBSaver\n",
    "checkpointer = MongoDBSaver.from_conn_string(\n",
    "    \"mongodb://localhost:27017\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dba1dec",
   "metadata": {},
   "source": [
    "## üéØ Esercizio Pratico\n",
    "\n",
    "Crea un agente che:\n",
    "\n",
    "1. Ha almeno UN tool personalizzato (scegli tu quale!)\n",
    "2. Ha un system prompt appropriato (magari con few-shot examples!)\n",
    "3. Usa la memoria per ricordare le interazioni\n",
    "4. *BONUS*: Restituisce output strutturati con Pydantic o formato controllato tramite prompt\n",
    "\n",
    "Idee per tools:\n",
    "- `search_wiki(query)` - cerca su Wikipedia (simulato)\n",
    "- `translate(text, target_lang)` - traduce testo\n",
    "- `get_recipe(dish)` - ottiene una ricetta\n",
    "- `convert_currency(amount, from_curr, to_curr)` - converte valuta\n",
    "- `generate_password(length)` - genera password sicura\n",
    "\n",
    "```python\n",
    "# Il tuo codice qui\n",
    "\n",
    "@tool\n",
    "def my_custom_tool(...):\n",
    "    \\\"\\\"\\\"...\\\"\\\"\\\"\n",
    "    pass\n",
    "\n",
    "# Crea l'agente\n",
    "my_agent = create_agent(...)\n",
    "\n",
    "# Testalo!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d23af57",
   "metadata": {},
   "source": [
    "## üìö Riepilogo\n",
    "\n",
    "In questa lezione hai imparato:\n",
    "\n",
    "- ‚úÖ **`init_chat_model`**: Inizializzare modelli con interfaccia unificata\n",
    "- ‚úÖ **Tools**: Creare funzioni che l'agente pu√≤ chiamare\n",
    "- ‚úÖ **System Prompts Avanzati**: Few-shot examples e controllo formato output\n",
    "- ‚úÖ **`create_agent`**: Creare agenti semplici e con tools\n",
    "- ‚úÖ **Output Strutturati**: Ottenere dati in formato JSON/Pydantic\n",
    "- ‚úÖ **Checkpointer**: Aggiungere memoria a breve termine\n",
    "- ‚úÖ **Thread ID**: Gestire conversazioni separate\n",
    "\n",
    "### üîë Concetti Chiave\n",
    "\n",
    "1. **Gli agenti LangChain sono costruiti su LangGraph** - ottieni robustezza e flessibilit√†\n",
    "2. **Inizia semplice, poi aggiungi tools** - costruisci incrementalmente\n",
    "3. **Few-shot examples guidano il comportamento** - usa 3-5 esempi di qualit√†\n",
    "4. **Prompt vs Pydantic per output** - scegli in base a flessibilit√† vs garanzie\n",
    "5. **La memoria √® essenziale per conversazioni naturali** - usa sempre checkpointer in produzione\n",
    "6. **Thread ID separate = conversazioni separate** - utile per applicazioni multi-utente"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-corso",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
